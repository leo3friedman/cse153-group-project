{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ebc366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import time\n",
    "from miditok.pytorch_data import DatasetMIDI, DataCollator\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "913d95ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress_bar(iteration, total, prefix='', length=50):\n",
    "    percent = (\"{0:.1f}\").format(100 * (iteration / float(total)))\n",
    "    filled_length = int(length * iteration // total)\n",
    "    bar = '█' * filled_length + '-' * (length - filled_length)\n",
    "    print(f'\\r{prefix} |{bar}| {percent}% Complete', end='\\r', flush=True)\n",
    "    if iteration == total:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f5a311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_midi_files(filepaths):\n",
    "    valid_files = []\n",
    "    for i, filepath in enumerate(filepaths):\n",
    "        try:\n",
    "            midi_data = pretty_midi.PrettyMIDI(filepath)\n",
    "            if len(midi_data.instruments) > 0:\n",
    "                valid_files.append(filepath)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filepath}: {e}\")\n",
    "        print_progress_bar(i+1, len(filepaths), prefix='Validating MIDI files')\n",
    "    return valid_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d899ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating MIDI files |--------------------------------------------------| 0.0% Complete\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing nesmdb_midi/train/122_FireEmblem_AnkokuRyutoHikarinoTsurugi_30_31EndingOmnibus.mid: MIDI file has a largest tick of 13007350, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/215_Magician_15_16EpiloguePart1.mid: MIDI file has a largest tick of 24797107, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/298_SolarJetman_HuntfortheGoldenWarpship_18_19LemonteGameplay.mid: MIDI file has a largest tick of 12682092, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/122_FireEmblem_AnkokuRyutoHikarinoTsurugi_28_29EndingOmnibusBallad.mid: MIDI file has a largest tick of 17014635, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/215_Magician_08_09MountVunarCavernsAbadonsCastle.mid: MIDI file has a largest tick of 16907305, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/405_ZombieNation_03_04VergeofDangerRoundSelect.mid: MIDI file has a largest tick of 18033915, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/104_FamicomJumpII_Saikyono7_nin_19_20ThemeofFriendshipEffortVictoryCreditRoll.mid: MIDI file has a largest tick of 12944249, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/298_SolarJetman_HuntfortheGoldenWarpship_12_13OmebruGameplay.mid: MIDI file has a largest tick of 66929847, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/329_SwordMaster_04_05MapScreen.mid: MIDI file has a largest tick of 26165568, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/314_SummerCarnival_92_Recca_13_14GelgoogScoreAttackSecondHalf.mid: MIDI file has a largest tick of 10957235, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/298_SolarJetman_HuntfortheGoldenWarpship_14_15CorsoQweroGameplay.mid: MIDI file has a largest tick of 14192721, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/314_SummerCarnival_92_Recca_08_09TeraArea2.mid: MIDI file has a largest tick of 12542620, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/201_LanMaster_01_02Gameplay.mid: MIDI file has a largest tick of 10742782, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/314_SummerCarnival_92_Recca_02_03JetterStage1FirstHalfArea5.mid: MIDI file has a largest tick of 12523014, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/091_DragonWarriorIV_43_44FinaleGuidingPeople.mid: MIDI file has a largest tick of 25710905, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/229_MegaMan6_35_36EndingOSTEdit.mid: MIDI file has a largest tick of 10348608, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/215_Magician_14_15AbadonBattleFinalBoss.mid: MIDI file has a largest tick of 11272539, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/314_SummerCarnival_92_Recca_12_13HienerScoreAttackFirstHalf.mid: MIDI file has a largest tick of 10001656, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/193_Klax_03_04DanceoftheFairies.mid: MIDI file has a largest tick of 18039578, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/064_DeepDungeonII_YuushinoMonshou_09_10DungeonFloor3.mid: MIDI file has a largest tick of 59777468, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/314_SummerCarnival_92_Recca_05_06HydeStage2Area6.mid: MIDI file has a largest tick of 13805692, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/298_SolarJetman_HuntfortheGoldenWarpship_09_10MexomorfGameplay.mid: MIDI file has a largest tick of 11175129, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/298_SolarJetman_HuntfortheGoldenWarpship_22_23ShishkebabGameplay.mid: MIDI file has a largest tick of 34300459, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/090_DragonWarriorIII_30_31IntoTheLegend.mid: MIDI file has a largest tick of 16605640, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/215_Magician_05_06TheLake.mid: MIDI file has a largest tick of 10755932, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/298_SolarJetman_HuntfortheGoldenWarpship_03_04PreludonGameplay.mid: MIDI file has a largest tick of 28131207, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/314_SummerCarnival_92_Recca_04_05MOMStage1SecondHalfArea3.mid: MIDI file has a largest tick of 11290582, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/117_FinalFantasy_17_18EndTheme.mid: MIDI file has a largest tick of 11324494, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/215_Magician_12_13CorridorofGates.mid: MIDI file has a largest tick of 14794736, it is likely corrupt\n",
      "Error processing nesmdb_midi/train/303_SpaceHarrier_02_03Theme.mid: MIDI file has a largest tick of 16906618, it is likely corrupt\n",
      "Validating MIDI files |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating MIDI files |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating MIDI files |██████████████████████████████████████████████████| 100.0% Complete\n"
     ]
    }
   ],
   "source": [
    "midi_dirpath = 'nesmdb_midi/'\n",
    "midi_train_dirpath = os.path.join(midi_dirpath, 'train')\n",
    "midi_test_dirpath = os.path.join(midi_dirpath, 'test')\n",
    "midi_val_dirpath = os.path.join(midi_dirpath, 'valid')\n",
    "midi_train_filesnames = os.listdir(midi_train_dirpath)\n",
    "midi_test_filesnames = os.listdir(midi_test_dirpath)\n",
    "midi_val_filenames = os.listdir(midi_val_dirpath)\n",
    "\n",
    "midi_train_filepaths = valid_midi_files([os.path.join(midi_train_dirpath, filename) for filename in midi_train_filesnames])\n",
    "midi_test_filepaths = valid_midi_files([os.path.join(midi_test_dirpath, filename) for filename in midi_test_filesnames])\n",
    "midi_val_filepaths = valid_midi_files([os.path.join(midi_val_dirpath, filename) for filename in midi_val_filenames])\n",
    "all_filepaths = midi_train_filepaths + midi_test_filepaths + midi_val_filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3098f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 1127\n",
      "Vocabulary: {'<PAD>': 0, '<BOS>': 1, '<EOS>': 2, 'time_shift_1': 3, 'time_shift_2': 4, 'time_shift_3': 5, 'time_shift_4': 6, 'time_shift_5': 7, 'time_shift_6': 8, 'time_shift_7': 9, 'time_shift_8': 10, 'time_shift_9': 11, 'time_shift_10': 12, 'time_shift_11': 13, 'time_shift_12': 14, 'time_shift_13': 15, 'time_shift_14': 16, 'time_shift_15': 17, 'time_shift_16': 18, 'time_shift_17': 19, 'time_shift_18': 20, 'time_shift_19': 21, 'time_shift_20': 22, 'time_shift_21': 23, 'time_shift_22': 24, 'time_shift_23': 25, 'time_shift_24': 26, 'time_shift_25': 27, 'time_shift_26': 28, 'time_shift_27': 29, 'time_shift_28': 30, 'time_shift_29': 31, 'time_shift_30': 32, 'time_shift_31': 33, 'time_shift_32': 34, 'time_shift_33': 35, 'time_shift_34': 36, 'time_shift_35': 37, 'time_shift_36': 38, 'time_shift_37': 39, 'time_shift_38': 40, 'time_shift_39': 41, 'time_shift_40': 42, 'time_shift_41': 43, 'time_shift_42': 44, 'time_shift_43': 45, 'time_shift_44': 46, 'time_shift_45': 47, 'time_shift_46': 48, 'time_shift_47': 49, 'time_shift_48': 50, 'time_shift_49': 51, 'time_shift_50': 52, 'time_shift_51': 53, 'time_shift_52': 54, 'time_shift_53': 55, 'time_shift_54': 56, 'time_shift_55': 57, 'time_shift_56': 58, 'time_shift_57': 59, 'time_shift_58': 60, 'time_shift_59': 61, 'time_shift_60': 62, 'time_shift_61': 63, 'time_shift_62': 64, 'time_shift_63': 65, 'time_shift_64': 66, 'time_shift_65': 67, 'time_shift_66': 68, 'time_shift_67': 69, 'time_shift_68': 70, 'time_shift_69': 71, 'time_shift_70': 72, 'time_shift_71': 73, 'time_shift_72': 74, 'time_shift_73': 75, 'time_shift_74': 76, 'time_shift_75': 77, 'time_shift_76': 78, 'time_shift_77': 79, 'time_shift_78': 80, 'time_shift_79': 81, 'time_shift_80': 82, 'time_shift_81': 83, 'time_shift_82': 84, 'time_shift_83': 85, 'time_shift_84': 86, 'time_shift_85': 87, 'time_shift_86': 88, 'time_shift_87': 89, 'time_shift_88': 90, 'time_shift_89': 91, 'time_shift_90': 92, 'time_shift_91': 93, 'time_shift_92': 94, 'time_shift_93': 95, 'time_shift_94': 96, 'time_shift_95': 97, 'time_shift_96': 98, 'time_shift_97': 99, 'time_shift_98': 100, 'time_shift_99': 101, 'time_shift_100': 102, 'note_on_0_instrument_80': 103, 'note_on_0_instrument_81': 104, 'note_on_0_instrument_38': 105, 'note_on_0_instrument_121': 106, 'note_on_1_instrument_80': 107, 'note_on_1_instrument_81': 108, 'note_on_1_instrument_38': 109, 'note_on_1_instrument_121': 110, 'note_on_2_instrument_80': 111, 'note_on_2_instrument_81': 112, 'note_on_2_instrument_38': 113, 'note_on_2_instrument_121': 114, 'note_on_3_instrument_80': 115, 'note_on_3_instrument_81': 116, 'note_on_3_instrument_38': 117, 'note_on_3_instrument_121': 118, 'note_on_4_instrument_80': 119, 'note_on_4_instrument_81': 120, 'note_on_4_instrument_38': 121, 'note_on_4_instrument_121': 122, 'note_on_5_instrument_80': 123, 'note_on_5_instrument_81': 124, 'note_on_5_instrument_38': 125, 'note_on_5_instrument_121': 126, 'note_on_6_instrument_80': 127, 'note_on_6_instrument_81': 128, 'note_on_6_instrument_38': 129, 'note_on_6_instrument_121': 130, 'note_on_7_instrument_80': 131, 'note_on_7_instrument_81': 132, 'note_on_7_instrument_38': 133, 'note_on_7_instrument_121': 134, 'note_on_8_instrument_80': 135, 'note_on_8_instrument_81': 136, 'note_on_8_instrument_38': 137, 'note_on_8_instrument_121': 138, 'note_on_9_instrument_80': 139, 'note_on_9_instrument_81': 140, 'note_on_9_instrument_38': 141, 'note_on_9_instrument_121': 142, 'note_on_10_instrument_80': 143, 'note_on_10_instrument_81': 144, 'note_on_10_instrument_38': 145, 'note_on_10_instrument_121': 146, 'note_on_11_instrument_80': 147, 'note_on_11_instrument_81': 148, 'note_on_11_instrument_38': 149, 'note_on_11_instrument_121': 150, 'note_on_12_instrument_80': 151, 'note_on_12_instrument_81': 152, 'note_on_12_instrument_38': 153, 'note_on_12_instrument_121': 154, 'note_on_13_instrument_80': 155, 'note_on_13_instrument_81': 156, 'note_on_13_instrument_38': 157, 'note_on_13_instrument_121': 158, 'note_on_14_instrument_80': 159, 'note_on_14_instrument_81': 160, 'note_on_14_instrument_38': 161, 'note_on_14_instrument_121': 162, 'note_on_15_instrument_80': 163, 'note_on_15_instrument_81': 164, 'note_on_15_instrument_38': 165, 'note_on_15_instrument_121': 166, 'note_on_16_instrument_80': 167, 'note_on_16_instrument_81': 168, 'note_on_16_instrument_38': 169, 'note_on_16_instrument_121': 170, 'note_on_17_instrument_80': 171, 'note_on_17_instrument_81': 172, 'note_on_17_instrument_38': 173, 'note_on_17_instrument_121': 174, 'note_on_18_instrument_80': 175, 'note_on_18_instrument_81': 176, 'note_on_18_instrument_38': 177, 'note_on_18_instrument_121': 178, 'note_on_19_instrument_80': 179, 'note_on_19_instrument_81': 180, 'note_on_19_instrument_38': 181, 'note_on_19_instrument_121': 182, 'note_on_20_instrument_80': 183, 'note_on_20_instrument_81': 184, 'note_on_20_instrument_38': 185, 'note_on_20_instrument_121': 186, 'note_on_21_instrument_80': 187, 'note_on_21_instrument_81': 188, 'note_on_21_instrument_38': 189, 'note_on_21_instrument_121': 190, 'note_on_22_instrument_80': 191, 'note_on_22_instrument_81': 192, 'note_on_22_instrument_38': 193, 'note_on_22_instrument_121': 194, 'note_on_23_instrument_80': 195, 'note_on_23_instrument_81': 196, 'note_on_23_instrument_38': 197, 'note_on_23_instrument_121': 198, 'note_on_24_instrument_80': 199, 'note_on_24_instrument_81': 200, 'note_on_24_instrument_38': 201, 'note_on_24_instrument_121': 202, 'note_on_25_instrument_80': 203, 'note_on_25_instrument_81': 204, 'note_on_25_instrument_38': 205, 'note_on_25_instrument_121': 206, 'note_on_26_instrument_80': 207, 'note_on_26_instrument_81': 208, 'note_on_26_instrument_38': 209, 'note_on_26_instrument_121': 210, 'note_on_27_instrument_80': 211, 'note_on_27_instrument_81': 212, 'note_on_27_instrument_38': 213, 'note_on_27_instrument_121': 214, 'note_on_28_instrument_80': 215, 'note_on_28_instrument_81': 216, 'note_on_28_instrument_38': 217, 'note_on_28_instrument_121': 218, 'note_on_29_instrument_80': 219, 'note_on_29_instrument_81': 220, 'note_on_29_instrument_38': 221, 'note_on_29_instrument_121': 222, 'note_on_30_instrument_80': 223, 'note_on_30_instrument_81': 224, 'note_on_30_instrument_38': 225, 'note_on_30_instrument_121': 226, 'note_on_31_instrument_80': 227, 'note_on_31_instrument_81': 228, 'note_on_31_instrument_38': 229, 'note_on_31_instrument_121': 230, 'note_on_32_instrument_80': 231, 'note_on_32_instrument_81': 232, 'note_on_32_instrument_38': 233, 'note_on_32_instrument_121': 234, 'note_on_33_instrument_80': 235, 'note_on_33_instrument_81': 236, 'note_on_33_instrument_38': 237, 'note_on_33_instrument_121': 238, 'note_on_34_instrument_80': 239, 'note_on_34_instrument_81': 240, 'note_on_34_instrument_38': 241, 'note_on_34_instrument_121': 242, 'note_on_35_instrument_80': 243, 'note_on_35_instrument_81': 244, 'note_on_35_instrument_38': 245, 'note_on_35_instrument_121': 246, 'note_on_36_instrument_80': 247, 'note_on_36_instrument_81': 248, 'note_on_36_instrument_38': 249, 'note_on_36_instrument_121': 250, 'note_on_37_instrument_80': 251, 'note_on_37_instrument_81': 252, 'note_on_37_instrument_38': 253, 'note_on_37_instrument_121': 254, 'note_on_38_instrument_80': 255, 'note_on_38_instrument_81': 256, 'note_on_38_instrument_38': 257, 'note_on_38_instrument_121': 258, 'note_on_39_instrument_80': 259, 'note_on_39_instrument_81': 260, 'note_on_39_instrument_38': 261, 'note_on_39_instrument_121': 262, 'note_on_40_instrument_80': 263, 'note_on_40_instrument_81': 264, 'note_on_40_instrument_38': 265, 'note_on_40_instrument_121': 266, 'note_on_41_instrument_80': 267, 'note_on_41_instrument_81': 268, 'note_on_41_instrument_38': 269, 'note_on_41_instrument_121': 270, 'note_on_42_instrument_80': 271, 'note_on_42_instrument_81': 272, 'note_on_42_instrument_38': 273, 'note_on_42_instrument_121': 274, 'note_on_43_instrument_80': 275, 'note_on_43_instrument_81': 276, 'note_on_43_instrument_38': 277, 'note_on_43_instrument_121': 278, 'note_on_44_instrument_80': 279, 'note_on_44_instrument_81': 280, 'note_on_44_instrument_38': 281, 'note_on_44_instrument_121': 282, 'note_on_45_instrument_80': 283, 'note_on_45_instrument_81': 284, 'note_on_45_instrument_38': 285, 'note_on_45_instrument_121': 286, 'note_on_46_instrument_80': 287, 'note_on_46_instrument_81': 288, 'note_on_46_instrument_38': 289, 'note_on_46_instrument_121': 290, 'note_on_47_instrument_80': 291, 'note_on_47_instrument_81': 292, 'note_on_47_instrument_38': 293, 'note_on_47_instrument_121': 294, 'note_on_48_instrument_80': 295, 'note_on_48_instrument_81': 296, 'note_on_48_instrument_38': 297, 'note_on_48_instrument_121': 298, 'note_on_49_instrument_80': 299, 'note_on_49_instrument_81': 300, 'note_on_49_instrument_38': 301, 'note_on_49_instrument_121': 302, 'note_on_50_instrument_80': 303, 'note_on_50_instrument_81': 304, 'note_on_50_instrument_38': 305, 'note_on_50_instrument_121': 306, 'note_on_51_instrument_80': 307, 'note_on_51_instrument_81': 308, 'note_on_51_instrument_38': 309, 'note_on_51_instrument_121': 310, 'note_on_52_instrument_80': 311, 'note_on_52_instrument_81': 312, 'note_on_52_instrument_38': 313, 'note_on_52_instrument_121': 314, 'note_on_53_instrument_80': 315, 'note_on_53_instrument_81': 316, 'note_on_53_instrument_38': 317, 'note_on_53_instrument_121': 318, 'note_on_54_instrument_80': 319, 'note_on_54_instrument_81': 320, 'note_on_54_instrument_38': 321, 'note_on_54_instrument_121': 322, 'note_on_55_instrument_80': 323, 'note_on_55_instrument_81': 324, 'note_on_55_instrument_38': 325, 'note_on_55_instrument_121': 326, 'note_on_56_instrument_80': 327, 'note_on_56_instrument_81': 328, 'note_on_56_instrument_38': 329, 'note_on_56_instrument_121': 330, 'note_on_57_instrument_80': 331, 'note_on_57_instrument_81': 332, 'note_on_57_instrument_38': 333, 'note_on_57_instrument_121': 334, 'note_on_58_instrument_80': 335, 'note_on_58_instrument_81': 336, 'note_on_58_instrument_38': 337, 'note_on_58_instrument_121': 338, 'note_on_59_instrument_80': 339, 'note_on_59_instrument_81': 340, 'note_on_59_instrument_38': 341, 'note_on_59_instrument_121': 342, 'note_on_60_instrument_80': 343, 'note_on_60_instrument_81': 344, 'note_on_60_instrument_38': 345, 'note_on_60_instrument_121': 346, 'note_on_61_instrument_80': 347, 'note_on_61_instrument_81': 348, 'note_on_61_instrument_38': 349, 'note_on_61_instrument_121': 350, 'note_on_62_instrument_80': 351, 'note_on_62_instrument_81': 352, 'note_on_62_instrument_38': 353, 'note_on_62_instrument_121': 354, 'note_on_63_instrument_80': 355, 'note_on_63_instrument_81': 356, 'note_on_63_instrument_38': 357, 'note_on_63_instrument_121': 358, 'note_on_64_instrument_80': 359, 'note_on_64_instrument_81': 360, 'note_on_64_instrument_38': 361, 'note_on_64_instrument_121': 362, 'note_on_65_instrument_80': 363, 'note_on_65_instrument_81': 364, 'note_on_65_instrument_38': 365, 'note_on_65_instrument_121': 366, 'note_on_66_instrument_80': 367, 'note_on_66_instrument_81': 368, 'note_on_66_instrument_38': 369, 'note_on_66_instrument_121': 370, 'note_on_67_instrument_80': 371, 'note_on_67_instrument_81': 372, 'note_on_67_instrument_38': 373, 'note_on_67_instrument_121': 374, 'note_on_68_instrument_80': 375, 'note_on_68_instrument_81': 376, 'note_on_68_instrument_38': 377, 'note_on_68_instrument_121': 378, 'note_on_69_instrument_80': 379, 'note_on_69_instrument_81': 380, 'note_on_69_instrument_38': 381, 'note_on_69_instrument_121': 382, 'note_on_70_instrument_80': 383, 'note_on_70_instrument_81': 384, 'note_on_70_instrument_38': 385, 'note_on_70_instrument_121': 386, 'note_on_71_instrument_80': 387, 'note_on_71_instrument_81': 388, 'note_on_71_instrument_38': 389, 'note_on_71_instrument_121': 390, 'note_on_72_instrument_80': 391, 'note_on_72_instrument_81': 392, 'note_on_72_instrument_38': 393, 'note_on_72_instrument_121': 394, 'note_on_73_instrument_80': 395, 'note_on_73_instrument_81': 396, 'note_on_73_instrument_38': 397, 'note_on_73_instrument_121': 398, 'note_on_74_instrument_80': 399, 'note_on_74_instrument_81': 400, 'note_on_74_instrument_38': 401, 'note_on_74_instrument_121': 402, 'note_on_75_instrument_80': 403, 'note_on_75_instrument_81': 404, 'note_on_75_instrument_38': 405, 'note_on_75_instrument_121': 406, 'note_on_76_instrument_80': 407, 'note_on_76_instrument_81': 408, 'note_on_76_instrument_38': 409, 'note_on_76_instrument_121': 410, 'note_on_77_instrument_80': 411, 'note_on_77_instrument_81': 412, 'note_on_77_instrument_38': 413, 'note_on_77_instrument_121': 414, 'note_on_78_instrument_80': 415, 'note_on_78_instrument_81': 416, 'note_on_78_instrument_38': 417, 'note_on_78_instrument_121': 418, 'note_on_79_instrument_80': 419, 'note_on_79_instrument_81': 420, 'note_on_79_instrument_38': 421, 'note_on_79_instrument_121': 422, 'note_on_80_instrument_80': 423, 'note_on_80_instrument_81': 424, 'note_on_80_instrument_38': 425, 'note_on_80_instrument_121': 426, 'note_on_81_instrument_80': 427, 'note_on_81_instrument_81': 428, 'note_on_81_instrument_38': 429, 'note_on_81_instrument_121': 430, 'note_on_82_instrument_80': 431, 'note_on_82_instrument_81': 432, 'note_on_82_instrument_38': 433, 'note_on_82_instrument_121': 434, 'note_on_83_instrument_80': 435, 'note_on_83_instrument_81': 436, 'note_on_83_instrument_38': 437, 'note_on_83_instrument_121': 438, 'note_on_84_instrument_80': 439, 'note_on_84_instrument_81': 440, 'note_on_84_instrument_38': 441, 'note_on_84_instrument_121': 442, 'note_on_85_instrument_80': 443, 'note_on_85_instrument_81': 444, 'note_on_85_instrument_38': 445, 'note_on_85_instrument_121': 446, 'note_on_86_instrument_80': 447, 'note_on_86_instrument_81': 448, 'note_on_86_instrument_38': 449, 'note_on_86_instrument_121': 450, 'note_on_87_instrument_80': 451, 'note_on_87_instrument_81': 452, 'note_on_87_instrument_38': 453, 'note_on_87_instrument_121': 454, 'note_on_88_instrument_80': 455, 'note_on_88_instrument_81': 456, 'note_on_88_instrument_38': 457, 'note_on_88_instrument_121': 458, 'note_on_89_instrument_80': 459, 'note_on_89_instrument_81': 460, 'note_on_89_instrument_38': 461, 'note_on_89_instrument_121': 462, 'note_on_90_instrument_80': 463, 'note_on_90_instrument_81': 464, 'note_on_90_instrument_38': 465, 'note_on_90_instrument_121': 466, 'note_on_91_instrument_80': 467, 'note_on_91_instrument_81': 468, 'note_on_91_instrument_38': 469, 'note_on_91_instrument_121': 470, 'note_on_92_instrument_80': 471, 'note_on_92_instrument_81': 472, 'note_on_92_instrument_38': 473, 'note_on_92_instrument_121': 474, 'note_on_93_instrument_80': 475, 'note_on_93_instrument_81': 476, 'note_on_93_instrument_38': 477, 'note_on_93_instrument_121': 478, 'note_on_94_instrument_80': 479, 'note_on_94_instrument_81': 480, 'note_on_94_instrument_38': 481, 'note_on_94_instrument_121': 482, 'note_on_95_instrument_80': 483, 'note_on_95_instrument_81': 484, 'note_on_95_instrument_38': 485, 'note_on_95_instrument_121': 486, 'note_on_96_instrument_80': 487, 'note_on_96_instrument_81': 488, 'note_on_96_instrument_38': 489, 'note_on_96_instrument_121': 490, 'note_on_97_instrument_80': 491, 'note_on_97_instrument_81': 492, 'note_on_97_instrument_38': 493, 'note_on_97_instrument_121': 494, 'note_on_98_instrument_80': 495, 'note_on_98_instrument_81': 496, 'note_on_98_instrument_38': 497, 'note_on_98_instrument_121': 498, 'note_on_99_instrument_80': 499, 'note_on_99_instrument_81': 500, 'note_on_99_instrument_38': 501, 'note_on_99_instrument_121': 502, 'note_on_100_instrument_80': 503, 'note_on_100_instrument_81': 504, 'note_on_100_instrument_38': 505, 'note_on_100_instrument_121': 506, 'note_on_101_instrument_80': 507, 'note_on_101_instrument_81': 508, 'note_on_101_instrument_38': 509, 'note_on_101_instrument_121': 510, 'note_on_102_instrument_80': 511, 'note_on_102_instrument_81': 512, 'note_on_102_instrument_38': 513, 'note_on_102_instrument_121': 514, 'note_on_103_instrument_80': 515, 'note_on_103_instrument_81': 516, 'note_on_103_instrument_38': 517, 'note_on_103_instrument_121': 518, 'note_on_104_instrument_80': 519, 'note_on_104_instrument_81': 520, 'note_on_104_instrument_38': 521, 'note_on_104_instrument_121': 522, 'note_on_105_instrument_80': 523, 'note_on_105_instrument_81': 524, 'note_on_105_instrument_38': 525, 'note_on_105_instrument_121': 526, 'note_on_106_instrument_80': 527, 'note_on_106_instrument_81': 528, 'note_on_106_instrument_38': 529, 'note_on_106_instrument_121': 530, 'note_on_107_instrument_80': 531, 'note_on_107_instrument_81': 532, 'note_on_107_instrument_38': 533, 'note_on_107_instrument_121': 534, 'note_on_108_instrument_80': 535, 'note_on_108_instrument_81': 536, 'note_on_108_instrument_38': 537, 'note_on_108_instrument_121': 538, 'note_on_109_instrument_80': 539, 'note_on_109_instrument_81': 540, 'note_on_109_instrument_38': 541, 'note_on_109_instrument_121': 542, 'note_on_110_instrument_80': 543, 'note_on_110_instrument_81': 544, 'note_on_110_instrument_38': 545, 'note_on_110_instrument_121': 546, 'note_on_111_instrument_80': 547, 'note_on_111_instrument_81': 548, 'note_on_111_instrument_38': 549, 'note_on_111_instrument_121': 550, 'note_on_112_instrument_80': 551, 'note_on_112_instrument_81': 552, 'note_on_112_instrument_38': 553, 'note_on_112_instrument_121': 554, 'note_on_113_instrument_80': 555, 'note_on_113_instrument_81': 556, 'note_on_113_instrument_38': 557, 'note_on_113_instrument_121': 558, 'note_on_114_instrument_80': 559, 'note_on_114_instrument_81': 560, 'note_on_114_instrument_38': 561, 'note_on_114_instrument_121': 562, 'note_on_115_instrument_80': 563, 'note_on_115_instrument_81': 564, 'note_on_115_instrument_38': 565, 'note_on_115_instrument_121': 566, 'note_on_116_instrument_80': 567, 'note_on_116_instrument_81': 568, 'note_on_116_instrument_38': 569, 'note_on_116_instrument_121': 570, 'note_on_117_instrument_80': 571, 'note_on_117_instrument_81': 572, 'note_on_117_instrument_38': 573, 'note_on_117_instrument_121': 574, 'note_on_118_instrument_80': 575, 'note_on_118_instrument_81': 576, 'note_on_118_instrument_38': 577, 'note_on_118_instrument_121': 578, 'note_on_119_instrument_80': 579, 'note_on_119_instrument_81': 580, 'note_on_119_instrument_38': 581, 'note_on_119_instrument_121': 582, 'note_on_120_instrument_80': 583, 'note_on_120_instrument_81': 584, 'note_on_120_instrument_38': 585, 'note_on_120_instrument_121': 586, 'note_on_121_instrument_80': 587, 'note_on_121_instrument_81': 588, 'note_on_121_instrument_38': 589, 'note_on_121_instrument_121': 590, 'note_on_122_instrument_80': 591, 'note_on_122_instrument_81': 592, 'note_on_122_instrument_38': 593, 'note_on_122_instrument_121': 594, 'note_on_123_instrument_80': 595, 'note_on_123_instrument_81': 596, 'note_on_123_instrument_38': 597, 'note_on_123_instrument_121': 598, 'note_on_124_instrument_80': 599, 'note_on_124_instrument_81': 600, 'note_on_124_instrument_38': 601, 'note_on_124_instrument_121': 602, 'note_on_125_instrument_80': 603, 'note_on_125_instrument_81': 604, 'note_on_125_instrument_38': 605, 'note_on_125_instrument_121': 606, 'note_on_126_instrument_80': 607, 'note_on_126_instrument_81': 608, 'note_on_126_instrument_38': 609, 'note_on_126_instrument_121': 610, 'note_on_127_instrument_80': 611, 'note_on_127_instrument_81': 612, 'note_on_127_instrument_38': 613, 'note_on_127_instrument_121': 614, 'note_off_0_instrument_80': 615, 'note_off_0_instrument_81': 616, 'note_off_0_instrument_38': 617, 'note_off_0_instrument_121': 618, 'note_off_1_instrument_80': 619, 'note_off_1_instrument_81': 620, 'note_off_1_instrument_38': 621, 'note_off_1_instrument_121': 622, 'note_off_2_instrument_80': 623, 'note_off_2_instrument_81': 624, 'note_off_2_instrument_38': 625, 'note_off_2_instrument_121': 626, 'note_off_3_instrument_80': 627, 'note_off_3_instrument_81': 628, 'note_off_3_instrument_38': 629, 'note_off_3_instrument_121': 630, 'note_off_4_instrument_80': 631, 'note_off_4_instrument_81': 632, 'note_off_4_instrument_38': 633, 'note_off_4_instrument_121': 634, 'note_off_5_instrument_80': 635, 'note_off_5_instrument_81': 636, 'note_off_5_instrument_38': 637, 'note_off_5_instrument_121': 638, 'note_off_6_instrument_80': 639, 'note_off_6_instrument_81': 640, 'note_off_6_instrument_38': 641, 'note_off_6_instrument_121': 642, 'note_off_7_instrument_80': 643, 'note_off_7_instrument_81': 644, 'note_off_7_instrument_38': 645, 'note_off_7_instrument_121': 646, 'note_off_8_instrument_80': 647, 'note_off_8_instrument_81': 648, 'note_off_8_instrument_38': 649, 'note_off_8_instrument_121': 650, 'note_off_9_instrument_80': 651, 'note_off_9_instrument_81': 652, 'note_off_9_instrument_38': 653, 'note_off_9_instrument_121': 654, 'note_off_10_instrument_80': 655, 'note_off_10_instrument_81': 656, 'note_off_10_instrument_38': 657, 'note_off_10_instrument_121': 658, 'note_off_11_instrument_80': 659, 'note_off_11_instrument_81': 660, 'note_off_11_instrument_38': 661, 'note_off_11_instrument_121': 662, 'note_off_12_instrument_80': 663, 'note_off_12_instrument_81': 664, 'note_off_12_instrument_38': 665, 'note_off_12_instrument_121': 666, 'note_off_13_instrument_80': 667, 'note_off_13_instrument_81': 668, 'note_off_13_instrument_38': 669, 'note_off_13_instrument_121': 670, 'note_off_14_instrument_80': 671, 'note_off_14_instrument_81': 672, 'note_off_14_instrument_38': 673, 'note_off_14_instrument_121': 674, 'note_off_15_instrument_80': 675, 'note_off_15_instrument_81': 676, 'note_off_15_instrument_38': 677, 'note_off_15_instrument_121': 678, 'note_off_16_instrument_80': 679, 'note_off_16_instrument_81': 680, 'note_off_16_instrument_38': 681, 'note_off_16_instrument_121': 682, 'note_off_17_instrument_80': 683, 'note_off_17_instrument_81': 684, 'note_off_17_instrument_38': 685, 'note_off_17_instrument_121': 686, 'note_off_18_instrument_80': 687, 'note_off_18_instrument_81': 688, 'note_off_18_instrument_38': 689, 'note_off_18_instrument_121': 690, 'note_off_19_instrument_80': 691, 'note_off_19_instrument_81': 692, 'note_off_19_instrument_38': 693, 'note_off_19_instrument_121': 694, 'note_off_20_instrument_80': 695, 'note_off_20_instrument_81': 696, 'note_off_20_instrument_38': 697, 'note_off_20_instrument_121': 698, 'note_off_21_instrument_80': 699, 'note_off_21_instrument_81': 700, 'note_off_21_instrument_38': 701, 'note_off_21_instrument_121': 702, 'note_off_22_instrument_80': 703, 'note_off_22_instrument_81': 704, 'note_off_22_instrument_38': 705, 'note_off_22_instrument_121': 706, 'note_off_23_instrument_80': 707, 'note_off_23_instrument_81': 708, 'note_off_23_instrument_38': 709, 'note_off_23_instrument_121': 710, 'note_off_24_instrument_80': 711, 'note_off_24_instrument_81': 712, 'note_off_24_instrument_38': 713, 'note_off_24_instrument_121': 714, 'note_off_25_instrument_80': 715, 'note_off_25_instrument_81': 716, 'note_off_25_instrument_38': 717, 'note_off_25_instrument_121': 718, 'note_off_26_instrument_80': 719, 'note_off_26_instrument_81': 720, 'note_off_26_instrument_38': 721, 'note_off_26_instrument_121': 722, 'note_off_27_instrument_80': 723, 'note_off_27_instrument_81': 724, 'note_off_27_instrument_38': 725, 'note_off_27_instrument_121': 726, 'note_off_28_instrument_80': 727, 'note_off_28_instrument_81': 728, 'note_off_28_instrument_38': 729, 'note_off_28_instrument_121': 730, 'note_off_29_instrument_80': 731, 'note_off_29_instrument_81': 732, 'note_off_29_instrument_38': 733, 'note_off_29_instrument_121': 734, 'note_off_30_instrument_80': 735, 'note_off_30_instrument_81': 736, 'note_off_30_instrument_38': 737, 'note_off_30_instrument_121': 738, 'note_off_31_instrument_80': 739, 'note_off_31_instrument_81': 740, 'note_off_31_instrument_38': 741, 'note_off_31_instrument_121': 742, 'note_off_32_instrument_80': 743, 'note_off_32_instrument_81': 744, 'note_off_32_instrument_38': 745, 'note_off_32_instrument_121': 746, 'note_off_33_instrument_80': 747, 'note_off_33_instrument_81': 748, 'note_off_33_instrument_38': 749, 'note_off_33_instrument_121': 750, 'note_off_34_instrument_80': 751, 'note_off_34_instrument_81': 752, 'note_off_34_instrument_38': 753, 'note_off_34_instrument_121': 754, 'note_off_35_instrument_80': 755, 'note_off_35_instrument_81': 756, 'note_off_35_instrument_38': 757, 'note_off_35_instrument_121': 758, 'note_off_36_instrument_80': 759, 'note_off_36_instrument_81': 760, 'note_off_36_instrument_38': 761, 'note_off_36_instrument_121': 762, 'note_off_37_instrument_80': 763, 'note_off_37_instrument_81': 764, 'note_off_37_instrument_38': 765, 'note_off_37_instrument_121': 766, 'note_off_38_instrument_80': 767, 'note_off_38_instrument_81': 768, 'note_off_38_instrument_38': 769, 'note_off_38_instrument_121': 770, 'note_off_39_instrument_80': 771, 'note_off_39_instrument_81': 772, 'note_off_39_instrument_38': 773, 'note_off_39_instrument_121': 774, 'note_off_40_instrument_80': 775, 'note_off_40_instrument_81': 776, 'note_off_40_instrument_38': 777, 'note_off_40_instrument_121': 778, 'note_off_41_instrument_80': 779, 'note_off_41_instrument_81': 780, 'note_off_41_instrument_38': 781, 'note_off_41_instrument_121': 782, 'note_off_42_instrument_80': 783, 'note_off_42_instrument_81': 784, 'note_off_42_instrument_38': 785, 'note_off_42_instrument_121': 786, 'note_off_43_instrument_80': 787, 'note_off_43_instrument_81': 788, 'note_off_43_instrument_38': 789, 'note_off_43_instrument_121': 790, 'note_off_44_instrument_80': 791, 'note_off_44_instrument_81': 792, 'note_off_44_instrument_38': 793, 'note_off_44_instrument_121': 794, 'note_off_45_instrument_80': 795, 'note_off_45_instrument_81': 796, 'note_off_45_instrument_38': 797, 'note_off_45_instrument_121': 798, 'note_off_46_instrument_80': 799, 'note_off_46_instrument_81': 800, 'note_off_46_instrument_38': 801, 'note_off_46_instrument_121': 802, 'note_off_47_instrument_80': 803, 'note_off_47_instrument_81': 804, 'note_off_47_instrument_38': 805, 'note_off_47_instrument_121': 806, 'note_off_48_instrument_80': 807, 'note_off_48_instrument_81': 808, 'note_off_48_instrument_38': 809, 'note_off_48_instrument_121': 810, 'note_off_49_instrument_80': 811, 'note_off_49_instrument_81': 812, 'note_off_49_instrument_38': 813, 'note_off_49_instrument_121': 814, 'note_off_50_instrument_80': 815, 'note_off_50_instrument_81': 816, 'note_off_50_instrument_38': 817, 'note_off_50_instrument_121': 818, 'note_off_51_instrument_80': 819, 'note_off_51_instrument_81': 820, 'note_off_51_instrument_38': 821, 'note_off_51_instrument_121': 822, 'note_off_52_instrument_80': 823, 'note_off_52_instrument_81': 824, 'note_off_52_instrument_38': 825, 'note_off_52_instrument_121': 826, 'note_off_53_instrument_80': 827, 'note_off_53_instrument_81': 828, 'note_off_53_instrument_38': 829, 'note_off_53_instrument_121': 830, 'note_off_54_instrument_80': 831, 'note_off_54_instrument_81': 832, 'note_off_54_instrument_38': 833, 'note_off_54_instrument_121': 834, 'note_off_55_instrument_80': 835, 'note_off_55_instrument_81': 836, 'note_off_55_instrument_38': 837, 'note_off_55_instrument_121': 838, 'note_off_56_instrument_80': 839, 'note_off_56_instrument_81': 840, 'note_off_56_instrument_38': 841, 'note_off_56_instrument_121': 842, 'note_off_57_instrument_80': 843, 'note_off_57_instrument_81': 844, 'note_off_57_instrument_38': 845, 'note_off_57_instrument_121': 846, 'note_off_58_instrument_80': 847, 'note_off_58_instrument_81': 848, 'note_off_58_instrument_38': 849, 'note_off_58_instrument_121': 850, 'note_off_59_instrument_80': 851, 'note_off_59_instrument_81': 852, 'note_off_59_instrument_38': 853, 'note_off_59_instrument_121': 854, 'note_off_60_instrument_80': 855, 'note_off_60_instrument_81': 856, 'note_off_60_instrument_38': 857, 'note_off_60_instrument_121': 858, 'note_off_61_instrument_80': 859, 'note_off_61_instrument_81': 860, 'note_off_61_instrument_38': 861, 'note_off_61_instrument_121': 862, 'note_off_62_instrument_80': 863, 'note_off_62_instrument_81': 864, 'note_off_62_instrument_38': 865, 'note_off_62_instrument_121': 866, 'note_off_63_instrument_80': 867, 'note_off_63_instrument_81': 868, 'note_off_63_instrument_38': 869, 'note_off_63_instrument_121': 870, 'note_off_64_instrument_80': 871, 'note_off_64_instrument_81': 872, 'note_off_64_instrument_38': 873, 'note_off_64_instrument_121': 874, 'note_off_65_instrument_80': 875, 'note_off_65_instrument_81': 876, 'note_off_65_instrument_38': 877, 'note_off_65_instrument_121': 878, 'note_off_66_instrument_80': 879, 'note_off_66_instrument_81': 880, 'note_off_66_instrument_38': 881, 'note_off_66_instrument_121': 882, 'note_off_67_instrument_80': 883, 'note_off_67_instrument_81': 884, 'note_off_67_instrument_38': 885, 'note_off_67_instrument_121': 886, 'note_off_68_instrument_80': 887, 'note_off_68_instrument_81': 888, 'note_off_68_instrument_38': 889, 'note_off_68_instrument_121': 890, 'note_off_69_instrument_80': 891, 'note_off_69_instrument_81': 892, 'note_off_69_instrument_38': 893, 'note_off_69_instrument_121': 894, 'note_off_70_instrument_80': 895, 'note_off_70_instrument_81': 896, 'note_off_70_instrument_38': 897, 'note_off_70_instrument_121': 898, 'note_off_71_instrument_80': 899, 'note_off_71_instrument_81': 900, 'note_off_71_instrument_38': 901, 'note_off_71_instrument_121': 902, 'note_off_72_instrument_80': 903, 'note_off_72_instrument_81': 904, 'note_off_72_instrument_38': 905, 'note_off_72_instrument_121': 906, 'note_off_73_instrument_80': 907, 'note_off_73_instrument_81': 908, 'note_off_73_instrument_38': 909, 'note_off_73_instrument_121': 910, 'note_off_74_instrument_80': 911, 'note_off_74_instrument_81': 912, 'note_off_74_instrument_38': 913, 'note_off_74_instrument_121': 914, 'note_off_75_instrument_80': 915, 'note_off_75_instrument_81': 916, 'note_off_75_instrument_38': 917, 'note_off_75_instrument_121': 918, 'note_off_76_instrument_80': 919, 'note_off_76_instrument_81': 920, 'note_off_76_instrument_38': 921, 'note_off_76_instrument_121': 922, 'note_off_77_instrument_80': 923, 'note_off_77_instrument_81': 924, 'note_off_77_instrument_38': 925, 'note_off_77_instrument_121': 926, 'note_off_78_instrument_80': 927, 'note_off_78_instrument_81': 928, 'note_off_78_instrument_38': 929, 'note_off_78_instrument_121': 930, 'note_off_79_instrument_80': 931, 'note_off_79_instrument_81': 932, 'note_off_79_instrument_38': 933, 'note_off_79_instrument_121': 934, 'note_off_80_instrument_80': 935, 'note_off_80_instrument_81': 936, 'note_off_80_instrument_38': 937, 'note_off_80_instrument_121': 938, 'note_off_81_instrument_80': 939, 'note_off_81_instrument_81': 940, 'note_off_81_instrument_38': 941, 'note_off_81_instrument_121': 942, 'note_off_82_instrument_80': 943, 'note_off_82_instrument_81': 944, 'note_off_82_instrument_38': 945, 'note_off_82_instrument_121': 946, 'note_off_83_instrument_80': 947, 'note_off_83_instrument_81': 948, 'note_off_83_instrument_38': 949, 'note_off_83_instrument_121': 950, 'note_off_84_instrument_80': 951, 'note_off_84_instrument_81': 952, 'note_off_84_instrument_38': 953, 'note_off_84_instrument_121': 954, 'note_off_85_instrument_80': 955, 'note_off_85_instrument_81': 956, 'note_off_85_instrument_38': 957, 'note_off_85_instrument_121': 958, 'note_off_86_instrument_80': 959, 'note_off_86_instrument_81': 960, 'note_off_86_instrument_38': 961, 'note_off_86_instrument_121': 962, 'note_off_87_instrument_80': 963, 'note_off_87_instrument_81': 964, 'note_off_87_instrument_38': 965, 'note_off_87_instrument_121': 966, 'note_off_88_instrument_80': 967, 'note_off_88_instrument_81': 968, 'note_off_88_instrument_38': 969, 'note_off_88_instrument_121': 970, 'note_off_89_instrument_80': 971, 'note_off_89_instrument_81': 972, 'note_off_89_instrument_38': 973, 'note_off_89_instrument_121': 974, 'note_off_90_instrument_80': 975, 'note_off_90_instrument_81': 976, 'note_off_90_instrument_38': 977, 'note_off_90_instrument_121': 978, 'note_off_91_instrument_80': 979, 'note_off_91_instrument_81': 980, 'note_off_91_instrument_38': 981, 'note_off_91_instrument_121': 982, 'note_off_92_instrument_80': 983, 'note_off_92_instrument_81': 984, 'note_off_92_instrument_38': 985, 'note_off_92_instrument_121': 986, 'note_off_93_instrument_80': 987, 'note_off_93_instrument_81': 988, 'note_off_93_instrument_38': 989, 'note_off_93_instrument_121': 990, 'note_off_94_instrument_80': 991, 'note_off_94_instrument_81': 992, 'note_off_94_instrument_38': 993, 'note_off_94_instrument_121': 994, 'note_off_95_instrument_80': 995, 'note_off_95_instrument_81': 996, 'note_off_95_instrument_38': 997, 'note_off_95_instrument_121': 998, 'note_off_96_instrument_80': 999, 'note_off_96_instrument_81': 1000, 'note_off_96_instrument_38': 1001, 'note_off_96_instrument_121': 1002, 'note_off_97_instrument_80': 1003, 'note_off_97_instrument_81': 1004, 'note_off_97_instrument_38': 1005, 'note_off_97_instrument_121': 1006, 'note_off_98_instrument_80': 1007, 'note_off_98_instrument_81': 1008, 'note_off_98_instrument_38': 1009, 'note_off_98_instrument_121': 1010, 'note_off_99_instrument_80': 1011, 'note_off_99_instrument_81': 1012, 'note_off_99_instrument_38': 1013, 'note_off_99_instrument_121': 1014, 'note_off_100_instrument_80': 1015, 'note_off_100_instrument_81': 1016, 'note_off_100_instrument_38': 1017, 'note_off_100_instrument_121': 1018, 'note_off_101_instrument_80': 1019, 'note_off_101_instrument_81': 1020, 'note_off_101_instrument_38': 1021, 'note_off_101_instrument_121': 1022, 'note_off_102_instrument_80': 1023, 'note_off_102_instrument_81': 1024, 'note_off_102_instrument_38': 1025, 'note_off_102_instrument_121': 1026, 'note_off_103_instrument_80': 1027, 'note_off_103_instrument_81': 1028, 'note_off_103_instrument_38': 1029, 'note_off_103_instrument_121': 1030, 'note_off_104_instrument_80': 1031, 'note_off_104_instrument_81': 1032, 'note_off_104_instrument_38': 1033, 'note_off_104_instrument_121': 1034, 'note_off_105_instrument_80': 1035, 'note_off_105_instrument_81': 1036, 'note_off_105_instrument_38': 1037, 'note_off_105_instrument_121': 1038, 'note_off_106_instrument_80': 1039, 'note_off_106_instrument_81': 1040, 'note_off_106_instrument_38': 1041, 'note_off_106_instrument_121': 1042, 'note_off_107_instrument_80': 1043, 'note_off_107_instrument_81': 1044, 'note_off_107_instrument_38': 1045, 'note_off_107_instrument_121': 1046, 'note_off_108_instrument_80': 1047, 'note_off_108_instrument_81': 1048, 'note_off_108_instrument_38': 1049, 'note_off_108_instrument_121': 1050, 'note_off_109_instrument_80': 1051, 'note_off_109_instrument_81': 1052, 'note_off_109_instrument_38': 1053, 'note_off_109_instrument_121': 1054, 'note_off_110_instrument_80': 1055, 'note_off_110_instrument_81': 1056, 'note_off_110_instrument_38': 1057, 'note_off_110_instrument_121': 1058, 'note_off_111_instrument_80': 1059, 'note_off_111_instrument_81': 1060, 'note_off_111_instrument_38': 1061, 'note_off_111_instrument_121': 1062, 'note_off_112_instrument_80': 1063, 'note_off_112_instrument_81': 1064, 'note_off_112_instrument_38': 1065, 'note_off_112_instrument_121': 1066, 'note_off_113_instrument_80': 1067, 'note_off_113_instrument_81': 1068, 'note_off_113_instrument_38': 1069, 'note_off_113_instrument_121': 1070, 'note_off_114_instrument_80': 1071, 'note_off_114_instrument_81': 1072, 'note_off_114_instrument_38': 1073, 'note_off_114_instrument_121': 1074, 'note_off_115_instrument_80': 1075, 'note_off_115_instrument_81': 1076, 'note_off_115_instrument_38': 1077, 'note_off_115_instrument_121': 1078, 'note_off_116_instrument_80': 1079, 'note_off_116_instrument_81': 1080, 'note_off_116_instrument_38': 1081, 'note_off_116_instrument_121': 1082, 'note_off_117_instrument_80': 1083, 'note_off_117_instrument_81': 1084, 'note_off_117_instrument_38': 1085, 'note_off_117_instrument_121': 1086, 'note_off_118_instrument_80': 1087, 'note_off_118_instrument_81': 1088, 'note_off_118_instrument_38': 1089, 'note_off_118_instrument_121': 1090, 'note_off_119_instrument_80': 1091, 'note_off_119_instrument_81': 1092, 'note_off_119_instrument_38': 1093, 'note_off_119_instrument_121': 1094, 'note_off_120_instrument_80': 1095, 'note_off_120_instrument_81': 1096, 'note_off_120_instrument_38': 1097, 'note_off_120_instrument_121': 1098, 'note_off_121_instrument_80': 1099, 'note_off_121_instrument_81': 1100, 'note_off_121_instrument_38': 1101, 'note_off_121_instrument_121': 1102, 'note_off_122_instrument_80': 1103, 'note_off_122_instrument_81': 1104, 'note_off_122_instrument_38': 1105, 'note_off_122_instrument_121': 1106, 'note_off_123_instrument_80': 1107, 'note_off_123_instrument_81': 1108, 'note_off_123_instrument_38': 1109, 'note_off_123_instrument_121': 1110, 'note_off_124_instrument_80': 1111, 'note_off_124_instrument_81': 1112, 'note_off_124_instrument_38': 1113, 'note_off_124_instrument_121': 1114, 'note_off_125_instrument_80': 1115, 'note_off_125_instrument_81': 1116, 'note_off_125_instrument_38': 1117, 'note_off_125_instrument_121': 1118, 'note_off_126_instrument_80': 1119, 'note_off_126_instrument_81': 1120, 'note_off_126_instrument_38': 1121, 'note_off_126_instrument_121': 1122, 'note_off_127_instrument_80': 1123, 'note_off_127_instrument_81': 1124, 'note_off_127_instrument_38': 1125, 'note_off_127_instrument_121': 1126}\n"
     ]
    }
   ],
   "source": [
    "TIME_SHIFT_RESOLUTION = 0.01  # 50 ms\n",
    "MAX_SHIFT_STEPS = 100  # Max 5 seconds\n",
    "BEGINNING_OF_SONG_TOKEN = '<BOS>'\n",
    "END_OF_SONG_TOKEN = '<EOS>'\n",
    "PAD_TOKEN = '<PAD>'\n",
    "VOCABULARY = dict()\n",
    "index = 0\n",
    "\n",
    "for special_token in [PAD_TOKEN, BEGINNING_OF_SONG_TOKEN, END_OF_SONG_TOKEN]:\n",
    "    VOCABULARY[special_token] = index\n",
    "    index += 1\n",
    "\n",
    "for time_shift in range(1, MAX_SHIFT_STEPS + 1):\n",
    "    VOCABULARY[f'time_shift_{time_shift}'] = index\n",
    "    index += 1\n",
    "\n",
    "for action in [\"note_on\", \"note_off\"]:\n",
    "    for pitch in range(128):\n",
    "        for program in [80, 81, 38, 121]:\n",
    "            VOCABULARY[f'{action}_{pitch}_instrument_{program}'] = index\n",
    "            index += 1\n",
    "\n",
    "print(f'Vocabulary size: {len(VOCABULARY)}')\n",
    "print(f'Vocabulary: {VOCABULARY}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "217eeec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_TO_TOKEN = {v: k for k, v in VOCABULARY.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "752166e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_to_tokens(pm: pretty_midi.PrettyMIDI):\n",
    "    events = []\n",
    "\n",
    "    for instrument in pm.instruments:\n",
    "        for note in instrument.notes:\n",
    "            events.append((note.start, f'note_on_{note.pitch}_instrument_{instrument.program}'))\n",
    "            events.append((note.end, f'note_off_{note.pitch}_instrument_{instrument.program}'))\n",
    "    \n",
    "    events.sort()  # Sort by time\n",
    "\n",
    "    tokens = []\n",
    "    last_time = 0.0\n",
    "    for time, event in events:\n",
    "        delta = time - last_time\n",
    "        steps = round(delta / TIME_SHIFT_RESOLUTION)\n",
    "\n",
    "        while steps > 0:\n",
    "            shift = min(steps, MAX_SHIFT_STEPS)\n",
    "            tokens.append(f'time_shift_{shift}')\n",
    "            steps -= shift\n",
    "        \n",
    "        tokens.append(event)\n",
    "        last_time = time\n",
    "    return [BEGINNING_OF_SONG_TOKEN] + tokens + [END_OF_SONG_TOKEN]\n",
    "\n",
    "def tokens_to_midi(tokens):\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    instruments = dict()\n",
    "    active_notes = dict()\n",
    "\n",
    "    current_time = 0.0\n",
    "    for token in tokens:\n",
    "        if token.startswith('time_shift_'):\n",
    "            shift_steps = int(token.split('_')[-1])\n",
    "            current_time += shift_steps * TIME_SHIFT_RESOLUTION\n",
    "        elif token.startswith('note_on_'):\n",
    "            pitch = int(token.split('_')[2])\n",
    "            instrument = int(token.split('_')[-1])\n",
    "            active_notes[(pitch, instrument)] = current_time\n",
    "        elif token.startswith('note_off_'):\n",
    "            pitch = int(token.split('_')[2])\n",
    "            instrument = int(token.split('_')[-1])\n",
    "            if (pitch, instrument) not in active_notes:\n",
    "                print(f\"Warning: Note off for {pitch} on instrument {instrument} without matching note on.\")\n",
    "                continue\n",
    "            start_time = active_notes[(pitch, instrument)]\n",
    "\n",
    "            if instrument not in instruments:\n",
    "                instruments[instrument] = pretty_midi.Instrument(program=instrument)\n",
    "\n",
    "            note = pretty_midi.Note(\n",
    "                velocity=100, pitch=pitch, start=start_time, end=current_time\n",
    "            )\n",
    "\n",
    "            instruments[instrument].notes.append(note)\n",
    "            \n",
    "    for instrument in instruments.values():\n",
    "        pm.instruments.append(instrument)\n",
    "    \n",
    "    return pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6adb1377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<BOS>', 'note_on_70_instrument_81', 'note_on_62_instrument_80', 'note_on_58_instrument_38', 'time_shift_37', 'note_off_58_instrument_38', 'time_shift_1', 'note_off_70_instrument_81', 'note_off_62_instrument_80', 'time_shift_2', 'note_on_70_instrument_81', 'note_on_62_instrument_80', 'note_on_58_instrument_38', 'time_shift_7', 'note_off_58_instrument_38', 'time_shift_1', 'note_off_70_instrument_81', 'note_off_62_instrument_80', 'time_shift_2', 'note_on_70_instrument_81', 'note_on_62_instrument_80', 'note_on_58_instrument_38', 'time_shift_7', 'note_off_58_instrument_38', 'time_shift_1', 'note_off_70_instrument_81', 'note_off_62_instrument_80', 'time_shift_2', 'note_on_70_instrument_81', 'note_on_62_instrument_80']\n"
     ]
    }
   ],
   "source": [
    "midi = pretty_midi.PrettyMIDI(all_filepaths[0])\n",
    "tokens = midi_to_tokens(midi)\n",
    "print(tokens[:30])\n",
    "midi_reconstructed = tokens_to_midi(tokens)\n",
    "# midi_reconstructed.write('reconstructed_midi.mid')\n",
    "# midi.write('original_midi.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc857af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sequences(filepaths):\n",
    "    sequences = []\n",
    "    for i, filepath in enumerate(filepaths):\n",
    "        pm = pretty_midi.PrettyMIDI(filepath)\n",
    "        tokens = midi_to_tokens(pm)\n",
    "        if not tokens:\n",
    "            raise ValueError(f'No tokens generated for {filepath}')\n",
    "        sequences.append([VOCABULARY[token] for token in tokens])\n",
    "        print_progress_bar(i+1, len(filepaths), prefix='Loading sequences')\n",
    "    return sequences\n",
    "\n",
    "class MIDITokenDataset(Dataset):\n",
    "    def __init__(self, sequences, seq_length=512):\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "        for ind, seq in enumerate(sequences):\n",
    "            num_chunks = len(seq) // (seq_length + 1)\n",
    "            for chunk in range(num_chunks + 1):\n",
    "                chunk_start = chunk * (seq_length + 1)\n",
    "                chunk_end = chunk_start + seq_length + 1\n",
    "                chunk = seq[chunk_start:chunk_end]\n",
    "\n",
    "                if len(chunk) < seq_length / 4:\n",
    "                    continue\n",
    "\n",
    "                input = chunk[:-1]\n",
    "                input = np.pad(input, (0, seq_length - len(input)), constant_values=VOCABULARY[PAD_TOKEN])\n",
    "                \n",
    "                target = chunk[1:]\n",
    "                target = np.pad(target, (0, seq_length - len(target)), constant_values=VOCABULARY[PAD_TOKEN])\n",
    "                \n",
    "                self.inputs.append(torch.tensor(input, dtype=torch.long))\n",
    "                self.targets.append(torch.tensor(target, dtype=torch.long))\n",
    "            \n",
    "            print_progress_bar(ind+1, len(sequences), prefix='Processing sequences')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6b488f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sequences |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Loading sequences |██████████████████████████████████████████████████| 100.0% Complete\n"
     ]
    }
   ],
   "source": [
    "# Load and convert\n",
    "train_sequences = load_sequences(midi_train_filepaths)\n",
    "val_sequences = load_sequences(midi_val_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0b0192f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sequences: 4470\n",
      "Train 90th percile length: 4361.699999999999\n",
      "Train 50th percile length: 944.0\n",
      "Train 25th percile length: 286.25\n",
      "Train 10th percile length: 99.0\n",
      "Train max train sequence length: 27506\n",
      "Train min train sequence length: 7\n",
      "Validation sequences: 402\n",
      "Validation 90th percile length: 4329.300000000001\n",
      "Validation 50th percile length: 682.0\n",
      "Validation 25th percile length: 176.0\n",
      "Validation 10th percile length: 73.0\n",
      "Validation max train sequence length: 14466\n",
      "Validation min train sequence length: 14\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def print_sequence_percentiles(sequences, prefix=''):\n",
    "    print(f'{prefix} sequences: {len(sequences)}')\n",
    "    print(f\"{prefix} 90th percile length: {np.percentile([len(seq) for seq in sequences], 90)}\")\n",
    "    print(f\"{prefix} 50th percile length: {np.percentile([len(seq) for seq in sequences], 50)}\")\n",
    "    print(f\"{prefix} 25th percile length: {np.percentile([len(seq) for seq in sequences], 25)}\")\n",
    "    print(f\"{prefix} 10th percile length: {np.percentile([len(seq) for seq in sequences], 10)}\")\n",
    "    print(f\"{prefix} max train sequence length: {max(len(seq) for seq in sequences)}\")\n",
    "    print(f\"{prefix} min train sequence length: {min(len(seq) for seq in sequences)}\")\n",
    "\n",
    "print_sequence_percentiles(train_sequences, prefix='Train')\n",
    "print_sequence_percentiles(val_sequences, prefix='Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acf1a698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sequences |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Processing sequences |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Train dataset size: 16287\n",
      "Validation dataset size: 1328\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "train_dataset = MIDITokenDataset(train_sequences, seq_length=512)\n",
    "val_dataset = MIDITokenDataset(val_sequences, seq_length=512)\n",
    "print(f'Train dataset size: {len(train_dataset)}')\n",
    "print(f'Validation dataset size: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "355a8948",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
    "        super(MusicRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        # x: (batch_size, seq_length)\n",
    "        x = self.embedding(x)  # (batch_size, seq_length, embedding_dim)\n",
    "        out, hidden = self.rnn(x, hidden)  # out: (batch_size, seq_length, hidden_dim)\n",
    "        out = self.fc(out)  # (batch_size, seq_length, vocab_size)\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2ff4f8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiny model parameters: 946,791\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from music_transformer_fixed import MusicTransformer\n",
    "\n",
    "\n",
    "def train_transformer(model, train_loader, val_loader, vocab_size, \n",
    "                     num_epochs=100, lr=0.001, device='cuda'):\n",
    "    \"\"\"\n",
    "    Training function adapted for MusicTransformer with progress bars and batch size handling\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        mems = None\n",
    "\n",
    "        for i, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # reset mems at sequence boundaries you care about\n",
    "            # e.g. if your loader shuffles songs:  mems = None\n",
    "\n",
    "            outputs, mems = model(inputs, mems=mems)\n",
    "            loss = criterion(outputs.view(-1, vocab_size),\n",
    "                            targets.view(-1))\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            # detach AFTER the backward pass\n",
    "            if mems is not None:\n",
    "                mems = [m.detach() for m in mems]\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            print_progress_bar(i+1, len(train_loader), prefix='Training...')\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            mems = None\n",
    "            for i, batch in enumerate(val_loader):\n",
    "                inputs, targets = batch\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                \n",
    "                \n",
    "                outputs, mems = model(inputs, mems=mems)\n",
    "                outputs = outputs.reshape(-1, vocab_size)\n",
    "                targets = targets.reshape(-1)\n",
    "                \n",
    "                loss = criterion(outputs.view(-1, vocab_size),\n",
    "                         targets.view(-1))\n",
    "                if mems is not None and mems[0].size(1) != inputs.size(0):\n",
    "                    mems = None\n",
    "                total_val_loss += loss.item()\n",
    "                \n",
    "                print_progress_bar(i+1, len(val_loader), prefix='Validating...')\n",
    "        \n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "def sample_transformer(model, start_token, max_length=1024, \n",
    "                      temperature=1.0, device='cuda'):\n",
    "    \"\"\"\n",
    "    Generate music using the transformer model\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    generated = [start_token]\n",
    "    input_token = torch.tensor([[start_token]], device=device)\n",
    "    \n",
    "    mems = None  # Initialize memory\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            # Get output and update memory\n",
    "            output, mems = model(input_token, mems=mems)\n",
    "            output = output[:, -1, :]  # Take the last output\n",
    "            output = output / temperature  # Adjust randomness\n",
    "            \n",
    "            probs = torch.nn.functional.softmax(output, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "            generated.append(next_token)\n",
    "            \n",
    "            # Check for end token (you'll need to define END_TOKEN)\n",
    "            # if next_token == END_TOKEN:\n",
    "            #     break\n",
    "            \n",
    "            input_token = torch.tensor([[next_token]], device=device)\n",
    "    print(generated)\n",
    "    return generated\n",
    "\n",
    "\n",
    "# Example usage\n",
    "xk = \"__main__\"\n",
    "if xk == \"__main__\":\n",
    "    # Configuration matching LakhNES\n",
    "    vocab_size = 1127  # From your vocabulary\n",
    "    \n",
    "    # Create model with LakhNES configuration\n",
    "    # model = MusicTransformer(\n",
    "    #     vocab_size=vocab_size,\n",
    "    #     d_model=512,\n",
    "    #     n_head=8,\n",
    "    #     d_head=64,\n",
    "    #     d_inner=2048,\n",
    "    #     n_layer=12,\n",
    "    #     dropout=0.1,\n",
    "    #     tgt_len=512,\n",
    "    #     mem_len=512,\n",
    "    #     tie_weight=True,\n",
    "    #     pre_lnorm=False\n",
    "    # )\n",
    "    \n",
    "    # # You can also create a smaller model for testing\n",
    "    # small_model = MusicTransformer(\n",
    "    #     vocab_size=vocab_size,\n",
    "    #     d_model=256,\n",
    "    #     n_head=4,\n",
    "    #     d_head=64,\n",
    "    #     d_inner=1024,\n",
    "    #     n_layer=6,\n",
    "    #     dropout=0.1,\n",
    "    #     tgt_len=256,\n",
    "    #     mem_len=256\n",
    "    # )\n",
    "\n",
    "    tiny_model = MusicTransformer(\n",
    "        vocab_size=vocab_size,\n",
    "        d_model=256,  # Keep same as small_model\n",
    "        n_head=4,     # Keep same as small_model\n",
    "        d_head=64,    # Keep same as small_model\n",
    "        d_inner=512, # Keep same as small_model\n",
    "        n_layer=1,    # Reduced from 6\n",
    "        dropout=0.1,\n",
    "        tgt_len=256,  # Keep same as small_model\n",
    "        mem_len=256   # Keep same as small_model\n",
    "    )\n",
    "\n",
    "    # print(f\"Full model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    # print(f\"Small model parameters: {sum(p.numel() for p in small_model.parameters()):,}\")\n",
    "    print(f\"Tiny model parameters: {sum(p.numel() for p in tiny_model.parameters()):,}\")\n",
    "    \n",
    "    # To use in your notebook, you would:\n",
    "    # 1. Import the MusicTransformer class\n",
    "    # 2. Replace MusicRNN with MusicTransformer\n",
    "    # 3. Use the adapted training and sampling functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3fe2681f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 1/100 | Train Loss: 4.2405 | Val Loss: 4.2089\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 2/100 | Train Loss: 3.8382 | Val Loss: 4.1873\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 3/100 | Train Loss: 3.7976 | Val Loss: 4.1831\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 4/100 | Train Loss: 3.7781 | Val Loss: 4.1647\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 5/100 | Train Loss: 3.7660 | Val Loss: 4.1531\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 6/100 | Train Loss: 3.7573 | Val Loss: 4.1586\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 7/100 | Train Loss: 3.7514 | Val Loss: 4.1298\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 8/100 | Train Loss: 3.7461 | Val Loss: 4.1548\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 9/100 | Train Loss: 3.7416 | Val Loss: 4.1577\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 10/100 | Train Loss: 3.7385 | Val Loss: 4.1593\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 11/100 | Train Loss: 3.7356 | Val Loss: 4.1558\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 12/100 | Train Loss: 3.7329 | Val Loss: 4.1527\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 13/100 | Train Loss: 3.7305 | Val Loss: 4.1475\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 14/100 | Train Loss: 3.7284 | Val Loss: 4.1299\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 15/100 | Train Loss: 3.7264 | Val Loss: 4.1492\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 16/100 | Train Loss: 3.7247 | Val Loss: 4.1435\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 17/100 | Train Loss: 3.7232 | Val Loss: 4.1428\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 18/100 | Train Loss: 3.7219 | Val Loss: 4.1409\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 19/100 | Train Loss: 3.7206 | Val Loss: 4.1412\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 20/100 | Train Loss: 3.7189 | Val Loss: 4.1373\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 21/100 | Train Loss: 3.7179 | Val Loss: 4.1386\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 22/100 | Train Loss: 3.7167 | Val Loss: 4.1286\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 23/100 | Train Loss: 3.7160 | Val Loss: 4.1254\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 24/100 | Train Loss: 3.7145 | Val Loss: 4.1268\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 25/100 | Train Loss: 3.7139 | Val Loss: 4.1515\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 26/100 | Train Loss: 3.7132 | Val Loss: 4.1114\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 27/100 | Train Loss: 3.7122 | Val Loss: 4.1453\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 28/100 | Train Loss: 3.7114 | Val Loss: 4.1262\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 29/100 | Train Loss: 3.7105 | Val Loss: 4.1268\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 30/100 | Train Loss: 3.7098 | Val Loss: 4.1287\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 31/100 | Train Loss: 3.7090 | Val Loss: 4.1455\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 32/100 | Train Loss: 3.7086 | Val Loss: 4.1206\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 33/100 | Train Loss: 3.7080 | Val Loss: 4.1606\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 34/100 | Train Loss: 3.7077 | Val Loss: 4.1410\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 35/100 | Train Loss: 3.7068 | Val Loss: 4.1407\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 36/100 | Train Loss: 3.7062 | Val Loss: 4.1316\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 37/100 | Train Loss: 3.7057 | Val Loss: 4.1360\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 38/100 | Train Loss: 3.7055 | Val Loss: 4.1222\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 39/100 | Train Loss: 3.7044 | Val Loss: 4.1376\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 40/100 | Train Loss: 3.7050 | Val Loss: 4.1345\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 41/100 | Train Loss: 3.7040 | Val Loss: 4.1313\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 42/100 | Train Loss: 3.7031 | Val Loss: 4.1494\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 43/100 | Train Loss: 3.7028 | Val Loss: 4.1289\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 44/100 | Train Loss: 3.7023 | Val Loss: 4.1459\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 45/100 | Train Loss: 3.7024 | Val Loss: 4.1236\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 46/100 | Train Loss: 3.7016 | Val Loss: 4.1416\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 47/100 | Train Loss: 3.7016 | Val Loss: 4.1308\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 48/100 | Train Loss: 3.7010 | Val Loss: 4.1156\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 49/100 | Train Loss: 3.7005 | Val Loss: 4.1399\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 50/100 | Train Loss: 3.7001 | Val Loss: 4.1393\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 51/100 | Train Loss: 3.6999 | Val Loss: 4.1330\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 52/100 | Train Loss: 3.6996 | Val Loss: 4.1332\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 53/100 | Train Loss: 3.6990 | Val Loss: 4.1393\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 54/100 | Train Loss: 3.6990 | Val Loss: 4.1297\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 55/100 | Train Loss: 3.6989 | Val Loss: 4.1478\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 56/100 | Train Loss: 3.6981 | Val Loss: 4.1248\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 57/100 | Train Loss: 3.6980 | Val Loss: 4.1465\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 58/100 | Train Loss: 3.6975 | Val Loss: 4.1466\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 59/100 | Train Loss: 3.6977 | Val Loss: 4.1457\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 60/100 | Train Loss: 3.6970 | Val Loss: 4.1476\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 61/100 | Train Loss: 3.6969 | Val Loss: 4.1301\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 62/100 | Train Loss: 3.6966 | Val Loss: 4.1354\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 63/100 | Train Loss: 3.6964 | Val Loss: 4.1525\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 64/100 | Train Loss: 3.6960 | Val Loss: 4.1351\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 65/100 | Train Loss: 3.6955 | Val Loss: 4.1302\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 66/100 | Train Loss: 3.6956 | Val Loss: 4.1415\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 67/100 | Train Loss: 3.6953 | Val Loss: 4.1432\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 68/100 | Train Loss: 3.6948 | Val Loss: 4.1191\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 69/100 | Train Loss: 3.6950 | Val Loss: 4.1396\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 70/100 | Train Loss: 3.6948 | Val Loss: 4.1387\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 71/100 | Train Loss: 3.6944 | Val Loss: 4.1301\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 72/100 | Train Loss: 3.6941 | Val Loss: 4.1229\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 73/100 | Train Loss: 3.6940 | Val Loss: 4.1361\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 74/100 | Train Loss: 3.6938 | Val Loss: 4.1326\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 75/100 | Train Loss: 3.6935 | Val Loss: 4.1266\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 76/100 | Train Loss: 3.6937 | Val Loss: 4.1296\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 77/100 | Train Loss: 3.6932 | Val Loss: 4.1309\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 78/100 | Train Loss: 3.6929 | Val Loss: 4.1309\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 79/100 | Train Loss: 3.6925 | Val Loss: 4.1130\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 80/100 | Train Loss: 3.6922 | Val Loss: 4.1569\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 81/100 | Train Loss: 3.6925 | Val Loss: 4.1312\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 82/100 | Train Loss: 3.6925 | Val Loss: 4.1239\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 83/100 | Train Loss: 3.6921 | Val Loss: 4.1435\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 84/100 | Train Loss: 3.6922 | Val Loss: 4.1284\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 85/100 | Train Loss: 3.6918 | Val Loss: 4.1261\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 86/100 | Train Loss: 3.6917 | Val Loss: 4.1276\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 87/100 | Train Loss: 3.6914 | Val Loss: 4.1233\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 88/100 | Train Loss: 3.6914 | Val Loss: 4.1433\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 89/100 | Train Loss: 3.6912 | Val Loss: 4.1522\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 90/100 | Train Loss: 3.6910 | Val Loss: 4.1398\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 91/100 | Train Loss: 3.6911 | Val Loss: 4.1364\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 92/100 | Train Loss: 3.6908 | Val Loss: 4.1314\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 93/100 | Train Loss: 3.6906 | Val Loss: 4.1313\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 94/100 | Train Loss: 3.6906 | Val Loss: 4.1546\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 95/100 | Train Loss: 3.6904 | Val Loss: 4.1262\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 96/100 | Train Loss: 3.6904 | Val Loss: 4.1429\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 97/100 | Train Loss: 3.6900 | Val Loss: 4.1356\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 98/100 | Train Loss: 3.6901 | Val Loss: 4.1340\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 99/100 | Train Loss: 3.6898 | Val Loss: 4.1342\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 100/100 | Train Loss: 3.6897 | Val Loss: 4.1158\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32  # You can adjust this depending on your GPU memory\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')\n",
    "train_transformer(tiny_model, train_loader, val_loader, vocab_size=len(VOCABULARY), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "28240435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating music from the transformer...\n",
      "[1, 162, 16, 162, 4, 162, 4, 162, 3, 626, 138, 277, 3, 674, 166, 841, 3, 839, 371, 883, 384, 289, 138, 4, 162, 4, 919, 411, 4, 785, 4, 793, 4, 265, 265, 777, 775, 4, 388, 900, 4, 392, 162, 9, 813, 10, 765, 3, 793, 8, 678, 162, 4, 796, 3, 162, 4, 285, 9, 138, 3, 887, 5, 297, 297, 3, 883, 363, 344, 3, 875, 471, 983, 379, 891, 383, 895, 5, 855, 4, 678, 6, 170, 682, 170, 3, 809, 3, 880, 4, 915, 4, 848, 4, 801, 7, 899, 4, 979, 3, 923, 9, 801, 4, 134, 4, 423, 935, 4, 920, 875, 4, 392, 12, 166, 7, 443, 3, 824, 4, 154, 4, 912, 404, 162, 317, 4, 400, 166, 285, 10, 3, 857, 8, 837, 4, 891, 4, 452, 964, 456, 4, 820, 4, 779, 263, 666, 6, 903, 387, 361, 8, 682, 162, 4, 861, 4, 313, 4, 388, 4, 733, 213, 4, 372, 154, 4, 408, 4, 396, 4, 158, 4, 781, 4, 924, 4, 439, 4, 416, 4, 900, 7, 843, 363, 130, 4, 455, 4, 162, 4, 912, 412, 134, 646, 4, 388, 16, 808, 809, 4, 166, 297, 4, 883, 371, 4, 900, 4, 380, 9, 146, 4, 856, 348, 154, 666, 4, 658, 150, 4, 908, 4, 316, 3, 118, 630, 9, 793, 4, 340, 4, 923, 435, 166, 166, 5, 396, 166, 14, 376, 4, 638, 150, 4, 670, 10, 352, 5, 793, 15, 793, 9, 771, 263, 4, 122, 4, 805, 4, 801, 7, 864, 5, 876, 4, 853, 4, 158, 4, 912, 915, 383, 4, 855, 4, 317, 162, 4, 404, 7, 915, 9, 626, 5, 126, 10, 809, 15, 837, 7, 781, 4, 809, 4, 670, 4, 674, 867, 9, 340, 5, 920, 2, 380, 10, 793, 4, 682, 3, 825, 4, 376, 17, 805, 5, 158, 4, 122, 3, 154, 4, 388, 7, 871, 3, 948, 6, 642, 3, 166, 313, 9, 805, 5, 674, 4, 678, 4, 856, 4, 166, 4, 420, 4, 325, 3, 829, 4, 666, 158, 4, 793, 3, 392, 4, 376, 7, 678, 16, 331, 14, 805, 5, 852, 4, 678, 14, 805, 3, 931, 4, 388, 9, 809, 9, 867, 4, 392, 355, 867, 4, 146, 25, 805, 4, 170, 4, 915, 4, 863, 4, 166, 9, 122, 4, 158, 4, 323, 20, 835, 9, 678, 4, 875, 5, 868, 4, 158, 4, 372, 701, 189, 9, 793, 15, 867, 4, 355, 7, 871, 20, 682, 10, 845, 9, 793, 8, 777, 7, 932, 4, 355, 8, 670, 158, 341, 3, 682, 5, 809, 8, 682, 16, 817, 7, 867, 4, 356, 10, 887, 4, 622, 7, 827, 315, 3, 868, 344, 835, 4, 355, 4, 158, 21, 678, 20, 356, 363, 4, 835, 4, 323, 9, 355, 4, 835, 4, 875, 4, 110, 4, 875, 7, 642, 9, 835, 4, 835, 4, 158, 4, 355, 9, 678, 4, 355, 166, 7, 678, 8, 170, 4, 130, 20, 952, 979, 4, 809, 4, 110, 4, 789, 10, 821, 5, 868, 4, 323, 7, 162, 4, 158, 325, 8, 356, 371, 9, 162, 4, 809, 7, 166, 4, 650, 34, 801, 4, 678, 158, 162, 363, 9, 793, 3, 654, 3, 827, 323, 20, 835, 4, 875, 9, 793, 9, 662, 14, 875, 4, 138, 8, 868, 166, 4, 162, 371, 12, 670, 9, 384, 8, 400, 835, 816, 4, 827, 319, 10, 682, 10, 821, 9, 323, 10, 678, 9, 678, 4, 682, 14, 931, 4, 355, 10, 662, 29, 883, 10, 162, 4, 883, 4, 813, 4, 867, 9, 944, 4, 372, 4, 323, 14, 883, 4, 662, 14, 372, 309, 3, 170, 8, 682, 29, 323, 8, 875, 355, 4, 883, 14, 883, 363, 162, 4, 371, 8, 9, 884, 5, 626, 21, 323, 9, 170, 4, 388, 9, 883, 20, 166, 8, 400, 14, 821, 3, 835, 4, 797, 8, 682, 8, 855, 7, 678, 14, 299, 14, 162, 419, 20, 805, 7, 835, 3, 170, 4, 836, 3, 323, 9, 654, 158, 8, 863, 323, 15, 835, 4, 650, 19, 835, 9, 9, 867, 4, 411, 20, 835, 323, 835, 29, 275, 5, 682, 10, 871, 29, 110, 4, 293, 4, 170, 4, 323, 15, 678, 20, 323, 10, 678, 102, 8, 166, 9, 863, 3, 305, 10, 831, 263, 22, 839, 9, 775, 7, 791, 323, 3, 670, 20, 805, 8, 682, 20, 421, 7, 323, 3, 654, 9, 835, 658, 17, 154, 10, 835, 8, 843, 359, 10, 852, 20, 755, 10, 654, 8, 150, 7, 682, 10, 831, 363, 4, 323, 8, 884, 336, 170, 15, 170, 8, 10, 170, 8, 678, 14, 263, 9, 835, 311, 10, 674, 9, 789, 9, 678, 29, 323, 10, 658, 14, 666, 15, 170, 9, 170, 15, 678, 8, 901, 3, 883, 4, 263, 7, 323, 9, 678, 8, 835, 816, 316, 4, 263, 22, 388, 775, 4, 380, 146, 9, 871, 14, 674, 20, 323, 29, 884, 7, 170, 8, 323, 20, 835, 14, 323, 8, 682, 15, 323, 12, 835, 263, 3, 835, 363, 875, 359, 20, 805, 14, 678, 20, 323, 14, 146, 10, 899, 359, 3, 674, 9, 827, 315, 9, 323, 15, 678, 27, 323, 27, 263, 7, 835, 315, 8, 678, 14, 678, 10, 170, 8, 275, 9, 8, 263, 22, 393, 12, 678, 14, 682, 10, 835, 311, 3, 166, 8, 323, 14, 658, 9, 835, 319, 3, 401, 401, 913, 409, 14, 835, 3, 263, 14, 323, 835, 9, 678, 10, 674, 7, 323, 8, 275, 883, 351, 401, 401, 255, 14, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 10, 263, 14, 856, 4, 654, 3, 777, 22, 162, 8, 682, 9, 835, 363, 20, 8, 682, 10, 875, 3, 162, 14, 323, 3, 913, 15, 666, 10, 863, 9, 110, 3, 371, 4, 835, 3, 363, 14, 883, 19, 871, 303, 15, 323, 27, 622, 23, 146, 7, 162, 3, 678, 11, 658, 8, 658, 3, 678, 170, 8, 170, 3, 883, 331, 3, 162, 15, 827, 315, 14, 323, 4, 323, 20, 835, 311, 823, 323, 835, 315, 4, 323, 900, 14, 331, 324, 324, 324, 324, 27, 323, 7, 809, 15, 323, 835, 4, 114, 8, 835, 3, 359, 22, 864, 14, 883, 331, 3, 670, 20, 662, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 10, 835, 9, 823, 323, 14, 835, 14, 884, 352, 352, 352, 352, 352, 20, 305, 8, 835, 4, 162, 4, 372, 15, 777, 7, 900, 4, 835, 363, 15, 170, 9, 263, 9, 900, 863, 315, 3, 835, 327, 12, 827, 315, 827, 315, 827, 315, 827, 315, 827, 315, 3, 835, 16, 166, 9, 323, 15, 835, 884, 22, 682, 9, 775, 134, 20, 142, 12, 323, 9, 884, 364, 14, 122, 8, 884, 376, 809, 7, 323, 4, 835, 315, 15, 875, 371, 864, 9, 162, 170, 8, 670, 14, 150, 7, 323, 14, 372, 4, 654, 3, 835, 315, 12, 323, 3, 682, 9, 146, 15, 622, 14, 114, 27, 311, 14, 323, 10, 363, 12, 835, 363, 22, 835, 9, 875, 323, 324, 323, 4, 835, 4, 883, 323, 10, 769, 170, 9, 323, 20, 904, 3, 170, 3, 674, 20, 835, 363, 4, 827, 311, 22, 142, 16, 323, 12, 118, 835, 315, 12, 913, 9, 835, 315, 4, 835, 4, 162, 4, 787, 315, 827, 323, 14, 646, 10, 146, 16, 777, 22, 913, 4, 303, 22, 150, 323, 20, 827, 323, 22, 678, 14, 118, 4, 372, 15, 835, 315, 827, 323, 9, 682, 14, 380, 9, 360, 7, 319, 14, 879, 2, 323, 380, 817, 3, 678, 658, 9, 323, 3, 678, 20, 359, 15, 835, 327, 15, 166, 9, 114, 20, 323, 14, 408, 9, 323, 4, 146, 4, 323, 14, 372, 15, 835, 4, 323, 3, 323, 9, 662, 146, 15, 835, 14, 142, 15, 363, 4, 654, 15, 126, 295, 12, 835, 327, 12, 319, 831, 315, 13, 263, 5, 134, 9, 905, 15, 775, 8, 162, 4, 363, 9, 162, 5, 630, 170, 12, 836, 304, 14, 674, 14, 372, 14, 817, 3, 146, 12, 315, 10, 658, 9, 678, 20, 658, 15, 146, 8, 905, 3, 678, 170, 5, 150, 150, 150, 150, 150, 14, 674, 8, 835, 311, 12, 777, 8, 654, 15, 359, 20, 162, 15, 658, 15, 852, 4, 674, 4, 118, 835, 4, 323, 835, 14, 682, 12, 118, 8, 297, 15, 323, 20, 323, 3, 835, 315, 14, 323, 4, 363, 9, 781, 20, 839, 319, 10, 835, 5, 857, 7, 654, 142, 15, 835, 22, 263, 372, 884, 364, 10, 670, 9, 781, 3, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 3, 646, 146, 15, 323, 22, 835, 363, 4, 835, 12, 777, 15, 674, 14, 773, 14, 809, 15, 162, 674, 323, 4, 658, 4, 311, 4, 674, 20, 372, 313, 10, 323, 9, 670, 10, 682, 7, 311, 388, 7, 884, 380, 9, 166, 4, 835, 323, 14, 305, 22, 891, 9, 670, 4, 658, 8, 875, 323, 3, 678, 7, 323, 22, 166, 9, 650, 20, 835, 816, 8, 839, 323, 3, 263, 372, 14, 828, 308, 451, 8, 360, 883, 363, 253, 9, 634, 4, 905, 401, 401, 401, 401, 401, 401, 401, 401, 913, 3, 323, 10, 162, 4, 323, 3, 678, 20, 146, 916, 916, 916, 916, 404, 146, 14, 363, 360, 323, 20, 835, 9, 371, 19, 263, 14, 650, 3, 162, 9, 110, 3, 654, 22, 864, 340, 301, 15, 900, 352, 352, 352, 835, 315, 9, 323, 5, 654, 9, 835, 311, 823, 7, 835, 275, 134, 20, 323, 22, 775, 4, 674, 3, 835, 311, 10, 162, 393, 9, 674, 8, 896, 8, 315, 14, 650, 20, 277, 3, 626, 16, 379, 4, 361, 4, 883, 372, 9, 359, 20, 170, 682, 8, 355, 325, 3, 658, 9, 884, 336, 122, 4, 835, 3, 162, 9, 821, 7, 815, 815, 815, 303, 15, 835, 319, 852, 9, 883, 363, 20, 674, 9, 170, 9, 650, 146, 4, 658, 9, 323, 4, 363, 384, 682, 14, 852, 7, 166, 9, 323, 22, 323, 5, 670, 20, 323, 4, 118, 8, 843, 856, 14, 835, 9, 670, 7, 851, 5, 371, 7, 323, 356, 868, 674, 19, 776, 4, 682, 22, 823, 315, 9, 323, 4, 323, 682, 9, 835, 9, 771, 8, 658, 12, 162, 14, 323, 835, 8, 363, 674, 8, 634, 7, 357, 8, 835, 315, 827, 315, 827, 315, 827, 315, 827, 315, 3, 835, 3, 170, 9, 658, 9, 170, 7, 323, 8, 836, 328, 15, 146, 658, 170, 16, 363, 7, 901, 15, 835, 9, 817, 3, 323, 10, 905, 14, 883, 327, 22, 146, 658, 8, 138, 15, 650, 20, 682, 134, 3, 162, 3, 670, 22, 8, 658, 9, 166, 678, 10, 658, 9, 323, 21, 840, 12, 835, 3, 162, 8, 835, 327, 20, 835, 4, 622, 14, 413, 22, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 9, 875, 363, 20, 835, 307, 3, 835, 363, 658, 9, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 275, 275, 275, 20, 864, 12, 682, 146, 14, 166, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 293, 22, 170, 323, 835, 323, 835, 323, 323, 912, 388, 388, 900, 384, 14, 323, 323, 323, 9, 658, 9, 658, 4, 372, 4, 146, 146, 7, 827, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 827, 827, 315, 315, 315, 315, 827, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 827, 315, 315, 827, 827, 315, 315, 315, 315, 315, 315, 315, 315, 827, 315, 7, 868, 14, 855, 323, 9, 817, 5, 305, 10, 863, 339, 352, 864, 372, 7, 821, 9, 666, 14, 827, 315, 827, 315, 827, 315, 827, 315, 827, 315, 827, 315, 827, 315, 827, 307, 4, 323, 301, 142, 401, 275, 9, 650, 309, 10, 317, 9, 658, 9, 305, 154, 8, 892, 384, 6, 817, 12, 401, 380, 162, 309, 10, 835, 315, 868, 372, 309, 14, 896, 4, 658, 7, 900, 2, 154, 309, 9, 323, 3, 658, 9, 654, 9, 892, 376, 5, 142, 9, 166, 257, 3, 263, 162, 9, 352, 7, 674, 775, 9, 658, 5, 134, 261, 7, 876, 372, 309, 3, 323, 4, 864, 344, 7, 815, 261, 8, 658, 3, 884, 528, 1040, 372, 162, 4, 835, 315, 827, 319, 980, 4, 307, 13, 827, 303, 7, 682, 142, 309, 3, 146, 305, 10, 363, 827, 319, 356, 7, 917, 401, 9, 835, 315, 162, 277, 3, 150, 6, 781, 3, 884, 364, 20, 835, 363, 316, 20, 896, 4, 823, 275, 150, 9, 323, 876, 344, 9, 835, 327, 142, 9, 674, 372, 249, 8, 769, 3, 372, 9, 851, 12, 815, 351, 9, 674, 9, 827, 323, 9, 332, 844, 14, 269, 8, 835, 315, 316, 4, 323, 4, 682, 4, 658, 9, 884, 384, 14, 142, 7, 8, 309, 10, 146, 4, 146, 441, 17, 384, 3, 146, 8, 892, 4, 654, 14, 789, 10, 917, 401, 9, 662, 9, 835, 9, 835, 315, 10, 662, 9, 905, 309, 9, 781, 6, 114, 8, 674, 146, 8, 835, 327, 14, 401, 401, 275, 9, 682, 12, 823, 4, 393, 5, 678, 20, 142, 4, 658, 16, 777, 15, 831, 14, 269, 14, 331, 22, 323, 72, 146, 20, 363, 5, 904, 388, 4, 263, 14, 303, 325, 9, 905, 12, 827, 323, 15, 323, 10, 323, 835, 9, 134, 12, 166, 269, 10, 767, 20, 827, 311, 823, 315, 7, 634, 14, 781, 13, 162, 4, 275, 15, 332, 844, 14, 835, 315, 14, 658, 10, 871, 323, 28, 170, 20, 257, 331, 15, 821, 9, 263, 4, 7, 134, 9, 263, 20, 170, 42, 835, 816, 4, 875, 327, 20, 831, 323, 14, 162, 3, 315, 827, 323, 4, 256, 767, 267, 20, 142, 9, 170, 912, 392, 20, 323, 24, 646, 20, 658, 14, 154, 4, 835, 327, 10, 835, 315, 4, 904, 400, 3, 654, 146, 4, 658, 14, 380, 4, 263, 20, 835, 315, 827, 323, 10, 682, 20, 678, 9, 162, 674, 4, 626, 323, 293, 3, 622, 166, 3, 323, 14, 146, 7, 817, 14, 162, 15, 815, 323, 14, 835, 319, 15, 313, 8, 158, 14, 678, 14, 323, 15, 932, 14, 848, 380, 162, 10, 323, 884, 158, 4, 363, 3, 767, 170, 14, 864, 4, 913, 4, 323, 14, 678, 8, 835, 3, 777, 8, 380, 166, 9, 905, 401, 275, 21, 883, 6, 372, 305, 4, 670, 17, 134, 263, 150, 150, 150, 150, 150, 150, 150, 150, 15, 851, 363, 5, 658, 22, 835, 3, 670, 9, 674, 9, 323, 8, 682, 20, 323, 8, 678, 15, 166, 8, 626, 9, 835, 307, 15, 263, 22, 871, 15, 331, 14, 883, 367, 20, 839, 327, 15, 913, 361, 3, 146, 10, 658, 4, 323, 9, 371, 15, 323, 4, 900, 4, 638, 9, 835, 315, 14, 638, 20, 888, 384, 9, 622, 20, 166, 401, 401, 275, 7, 851, 20, 400, 15, 678, 13, 323, 8, 831, 323, 9, 875, 263, 3, 323, 20, 351, 8, 658, 20, 361, 8, 682, 24, 777, 15, 622, 7, 405, 405, 405, 405, 10, 323, 10, 363, 15, 323, 6, 654, 4, 323, 9, 682, 14, 150, 150, 150, 150, 150, 150, 150, 150, 150, 9, 670, 4, 323, 9, 883, 331, 162, 9, 678, 4, 622, 15, 678, 24, 871, 9, 323, 9, 658, 8, 678, 14, 863, 4, 110, 15, 110, 15, 351, 305, 8, 166, 678, 16, 835, 13, 817, 12, 166, 4, 835, 4, 622, 9, 831, 323, 14, 323, 14, 323, 4, 323, 15, 805, 10, 678, 21, 871, 323, 9, 323, 8, 170, 20, 162, 10, 863, 9, 816, 332, 22, 371, 9, 150, 14, 118, 9, 777, 8, 674, 22, 835, 4, 622, 14, 323, 162, 9, 807, 275, 22, 380, 658, 4, 146, 8, 654, 9, 884, 528, 1040, 372, 9, 134, 9, 275, 9, 666, 363, 9, 323, 15, 892, 332, 20, 162, 7, 662, 3, 658, 14, 816, 891, 9, 14, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 11, 884, 528, 1040, 372, 9, 646, 14, 835, 3, 871, 9, 162, 8, 789, 9, 265, 15, 154, 10, 913, 8, 787, 279, 8, 883, 375, 154, 27, 166, 14, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 275, 10, 678, 8, 682, 170, 323, 118, 332, 311, 823, 311, 22, 904, 323, 15, 658, 3, 654, 323, 22, 835, 363, 884, 356, 20, 255, 15, 835, 343, 22, 295, 14, 371, 658, 10, 263, 15, 323, 323, 10, 170, 323, 9, 658, 4, 658, 5, 110, 8, 323, 3, 884, 4, 170, 351, 4, 323, 376, 162, 323, 835, 4, 323, 323, 12, 363, 134, 7, 827, 315, 315, 315, 315, 315, 315, 827, 827, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 827, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 315, 827, 315, 827, 315, 827, 315, 827, 315, 827, 315, 827, 315, 10, 768, 20, 682, 9, 835, 323, 14, 884, 9, 630, 12, 401, 401, 401, 401, 401, 401, 401, 401, 401, 275, 150, 150, 372, 8, 829, 5, 884, 7, 642, 7, 823, 323, 12, 913, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 275, 14, 835, 658, 9, 835, 323, 307, 8, 323, 305, 14, 682, 323, 835, 323, 5, 682, 658, 10, 146, 146, 146, 658, 15, 14, 650, 9, 876, 876, 876, 12, 658, 146, 10, 821, 4, 658, 9, 864, 360, 835, 295, 14, 888, 10, 142, 9, 835, 315, 10, 876, 10, 146, 9, 835, 315, 827, 323, 835, 315, 827, 307, 4, 323, 10, 658, 8, 864, 364, 150, 4, 323, 892, 380, 150, 658, 10, 884, 14, 835, 315, 827, 303, 904, 4, 146, 10, 323, 14, 905, 401, 401, 275, 150, 9, 876, 4, 401, 275, 4, 682, 10, 868, 372, 393, 8, 835, 15, 323, 380, 154, 9, 896, 4, 323, 10, 351, 138, 4, 323, 868, 5, 843, 323, 856, 4, 138, 325, 10, 682, 20, 771, 275, 10, 884, 528, 1040, 372, 14, 658, 9, 114, 269, 10, 835, 9, 331, 10, 835, 315, 10, 781, 10, 162, 844, 372, 14, 863, 896, 14, 875, 323, 4, 315, 8, 835, 327, 413, 10, 626, 9, 372, 14, 372, 146, 9, 855, 323, 868, 4, 658, 4, 864, 356, 309, 10, 863, 323, 5, 877, 10, 658, 12, 658, 142, 309, 4, 319, 674, 323, 15, 835, 315, 827, 323, 305, 8, 835, 315, 827, 323, 5, 372, 166, 4, 146, 9, 678, 817, 9, 678, 4, 884, 328, 9, 658, 4, 146, 9, 857, 309, 10, 867, 339, 4, 913, 3, 864, 4, 658, 10, 355, 888, 376, 888, 884, 380, 14, 162, 257, 20, 658, 4, 372, 154, 13, 835, 343, 855, 363, 20, 827, 315, 10, 875, 323, 4, 835, 315, 10, 392, 15, 658, 7, 940, 352, 12, 279, 20, 827, 315, 7, 913, 393, 8, 835, 315, 827, 315, 4, 884, 364, 14, 913, 14, 835, 307, 22, 678, 4, 263, 372, 162, 11, 682, 21, 844, 316, 4, 138, 8, 146, 7, 162, 22, 682, 162, 4, 658, 7, 118, 5, 809, 313, 162, 9, 767, 323, 10, 787, 279, 868, 9, 646, 7, 875, 323, 4, 884, 376, 146, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 8, 879, 363, 875, 323, 835, 327, 355, 831, 323, 9, 142, 9, 372, 166, 10, 146, 309, 122, 9, 162, 7, 831, 315, 15, 856, 4, 4, 138, 4, 622, 118, 528, 1040, 372, 9, 883, 331, 4, 138, 650, 142, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 13, 150, 150, 150, 150, 150, 150, 150, 150, 150, 10, 773, 5, 142, 9, 658, 166, 4, 875, 323, 879, 371, 372, 884, 336, 848, 340, 339, 324, 4, 674, 10, 791, 311, 823, 323, 864, 340, 835, 311, 823, 319, 261, 9, 835, 323, 6, 114, 4, 162, 4, 773, 3, 839, 323, 356, 261, 3, 158, 325, 863, 343, 9, 839, 323, 6, 825, 35, 372, 14, 150, 150, 150, 9, 781, 14, 821, 20, 773, 9, 355, 134, 10, 805, 14, 884, 364, 4, 371, 884, 364, 150, 3, 259, 771, 255, 4, 372, 110, 9, 162, 4, 371, 166, 884, 360, 4, 315, 827, 315, 4, 622, 835, 3, 829, 8, 654, 9, 787, 7, 773, 5, 773, 9, 769, 4, 654, 3, 674, 9, 789, 4, 166, 4, 393, 15, 372, 162, 4, 875, 323, 22, 769, 9, 835, 9, 821, 5, 836, 3, 863, 343, 162, 4, 815, 307, 9, 835, 3, 884, 4, 827, 315, 15, 162, 4, 827, 315, 4, 827, 315, 4, 905, 8, 305, 12, 670, 9, 134, 20, 307, 3, 158, 392, 22, 887, 331, 22, 843, 379, 265, 14, 323, 3, 162, 4, 622, 11, 817, 3, 883, 363, 4, 380, 20, 134, 324, 20, 162, 4, 352, 352, 352, 864, 4, 363, 384, 371, 22, 848, 19, 154, 154, 154, 3, 130, 369, 4, 372, 9, 871, 3, 162, 4, 371, 9, 809, 8, 923, 809, 14, 847, 343, 10, 351, 863, 363, 42, 809, 8, 835, 315, 4, 670, 4, 323, 4, 392, 4, 138, 15, 793, 4, 166, 7, 892, 4, 150, 150, 150, 150, 150, 150, 14, 835, 315, 4, 662, 154, 5, 835, 4, 297, 3, 324, 9, 777, 4, 835, 4, 323, 372, 884, 875, 4, 372, 4, 281, 3, 351, 4, 891, 355, 22, 323, 4, 836, 10, 835, 307, 3, 883, 9, 781, 9, 674, 22, 162, 9, 793, 15, 827, 315, 4, 162, 4, 158, 781, 15, 114, 4, 857, 50, 797, 4, 829, 8, 638, 15, 835, 816, 3, 323, 3, 371, 14, 371, 3, 682, 12, 622, 110, 20, 273, 3, 277, 3, 817, 12, 638, 29, 170, 4, 323, 8, 835, 4, 275, 4, 372, 883, 363, 10, 682, 14, 662, 9, 323, 4, 682, 8, 868, 352, 305, 4, 836, 22, 269, 5, 839, 42, 134, 21, 844, 9, 658, 20, 162, 4, 658, 20, 678, 8, 323, 15, 162, 9, 162, 4, 674, 22, 789, 10, 393, 9, 932, 4, 142, 20, 372, 884, 2, 323, 304, 3, 682, 14, 662, 15, 339, 682, 20, 323, 20]\n",
      "Hit end token at position 303\n",
      "\n",
      "Converting to MIDI...\n",
      "Warning: Note off for 2 on instrument 121 without matching note on.\n",
      "Warning: Note off for 56 on instrument 38 without matching note on.\n",
      "Warning: Note off for 56 on instrument 80 without matching note on.\n",
      "Warning: Note off for 76 on instrument 80 without matching note on.\n",
      "Warning: Note off for 42 on instrument 38 without matching note on.\n",
      "Warning: Note off for 44 on instrument 38 without matching note on.\n",
      "Warning: Note off for 40 on instrument 80 without matching note on.\n",
      "Warning: Note off for 49 on instrument 38 without matching note on.\n",
      "Warning: Note off for 37 on instrument 38 without matching note on.\n",
      "Warning: Note off for 44 on instrument 38 without matching note on.\n",
      "Warning: Note off for 45 on instrument 81 without matching note on.\n",
      "Warning: Note off for 68 on instrument 80 without matching note on.\n",
      "Warning: Note off for 60 on instrument 80 without matching note on.\n",
      "Warning: Note off for 66 on instrument 81 without matching note on.\n",
      "Warning: Note off for 75 on instrument 80 without matching note on.\n",
      "Warning: Note off for 58 on instrument 81 without matching note on.\n",
      "Warning: Note off for 71 on instrument 80 without matching note on.\n",
      "Warning: Note off for 91 on instrument 80 without matching note on.\n",
      "Warning: Note off for 76 on instrument 81 without matching note on.\n",
      "Warning: Note off for 52 on instrument 81 without matching note on.\n",
      "Warning: Note off for 74 on instrument 81 without matching note on.\n",
      "Warning: Note off for 60 on instrument 38 without matching note on.\n",
      "Warning: Note off for 55 on instrument 38 without matching note on.\n",
      "Warning: Note off for 51 on instrument 81 without matching note on.\n",
      "Warning: Note off for 41 on instrument 80 without matching note on.\n",
      "Warning: Note off for 72 on instrument 80 without matching note on.\n",
      "Warning: Note off for 61 on instrument 38 without matching note on.\n",
      "Warning: Note off for 29 on instrument 38 without matching note on.\n",
      "Warning: Note off for 41 on instrument 38 without matching note on.\n",
      "Warning: Note off for 77 on instrument 81 without matching note on.\n",
      "Warning: Note off for 57 on instrument 80 without matching note on.\n",
      "Warning: Note off for 48 on instrument 81 without matching note on.\n",
      "Warning: Note off for 44 on instrument 38 without matching note on.\n",
      "Warning: Note off for 5 on instrument 121 without matching note on.\n",
      "Warning: Note off for 44 on instrument 38 without matching note on.\n",
      "Warning: Note off for 44 on instrument 38 without matching note on.\n",
      "Warning: Note off for 39 on instrument 80 without matching note on.\n",
      "Warning: Note off for 47 on instrument 38 without matching note on.\n",
      "Warning: Note off for 65 on instrument 81 without matching note on.\n",
      "Warning: Note off for 59 on instrument 38 without matching note on.\n",
      "Warning: Note off for 75 on instrument 80 without matching note on.\n",
      "Warning: Note off for 60 on instrument 80 without matching note on.\n",
      "Warning: Note off for 75 on instrument 80 without matching note on.\n",
      "Warning: Note off for 2 on instrument 121 without matching note on.\n",
      "Warning: Note off for 55 on instrument 38 without matching note on.\n",
      "Warning: Note off for 41 on instrument 38 without matching note on.\n",
      "Warning: Note off for 63 on instrument 80 without matching note on.\n",
      "Warning: Note off for 44 on instrument 38 without matching note on.\n",
      "Warning: Note off for 47 on instrument 38 without matching note on.\n",
      "Warning: Note off for 64 on instrument 80 without matching note on.\n",
      "Warning: Note off for 83 on instrument 81 without matching note on.\n",
      "Warning: Note off for 47 on instrument 38 without matching note on.\n",
      "Warning: Note off for 44 on instrument 38 without matching note on.\n",
      "Warning: Note off for 47 on instrument 38 without matching note on.\n",
      "Warning: Note off for 47 on instrument 38 without matching note on.\n",
      "Warning: Note off for 79 on instrument 80 without matching note on.\n",
      "Warning: Note off for 63 on instrument 80 without matching note on.\n",
      "Warning: Note off for 47 on instrument 38 without matching note on.\n",
      "Warning: Note off for 75 on instrument 80 without matching note on.\n",
      "Warning: Note off for 62 on instrument 80 without matching note on.\n",
      "Warning: Note off for 63 on instrument 81 without matching note on.\n",
      "Warning: Note off for 21 on instrument 38 without matching note on.\n",
      "Warning: Note off for 44 on instrument 38 without matching note on.\n",
      "Warning: Note off for 64 on instrument 80 without matching note on.\n",
      "Warning: Note off for 57 on instrument 38 without matching note on.\n",
      "Warning: Note off for 44 on instrument 38 without matching note on.\n",
      "Warning: Note off for 50 on instrument 38 without matching note on.\n",
      "Warning: Note off for 68 on instrument 80 without matching note on.\n",
      "Warning: Note off for 1 on instrument 121 without matching note on.\n",
      "Warning: Note off for 53 on instrument 80 without matching note on.\n",
      "Warning: Note off for 84 on instrument 81 without matching note on.\n",
      "Warning: Note off for 91 on instrument 80 without matching note on.\n",
      "Warning: Note off for 51 on instrument 38 without matching note on.\n",
      "Warning: Note off for 44 on instrument 38 without matching note on.\n",
      "Warning: Note off for 9 on instrument 121 without matching note on.\n",
      "Warning: Note off for 44 on instrument 38 without matching note on.\n",
      "Warning: Note off for 50 on instrument 81 without matching note on.\n",
      "Warning: Note off for 51 on instrument 38 without matching note on.\n",
      "Warning: Note off for 79 on instrument 80 without matching note on.\n",
      "Warning: Note off for 49 on instrument 38 without matching note on.\n",
      "Warning: Note off for 82 on instrument 81 without matching note on.\n",
      "Warning: Note off for 2 on instrument 121 without matching note on.\n",
      "Warning: Note off for 60 on instrument 80 without matching note on.\n",
      "Warning: Note off for 47 on instrument 38 without matching note on.\n",
      "Warning: Note off for 55 on instrument 81 without matching note on.\n",
      "Warning: Note off for 9 on instrument 121 without matching note on.\n",
      "Warning: Note off for 62 on instrument 80 without matching note on.\n",
      "Warning: Note off for 64 on instrument 80 without matching note on.\n",
      "Warning: Note off for 62 on instrument 80 without matching note on.\n",
      "Warning: Note off for 56 on instrument 80 without matching note on.\n",
      "Warning: Note off for 44 on instrument 80 without matching note on.\n",
      "Warning: Note off for 9 on instrument 121 without matching note on.\n",
      "Warning: Note off for 35 on instrument 80 without matching note on.\n",
      "Warning: Note off for 9 on instrument 121 without matching note on.\n",
      "Warning: Note off for 71 on instrument 38 without matching note on.\n",
      "Warning: Note off for 50 on instrument 81 without matching note on.\n",
      "Warning: Note off for 9 on instrument 121 without matching note on.\n",
      "Warning: Note off for 38 on instrument 38 without matching note on.\n",
      "Warning: Note off for 66 on instrument 80 without matching note on.\n",
      "Warning: Note off for 41 on instrument 38 without matching note on.\n",
      "Warning: Note off for 60 on instrument 38 without matching note on.\n",
      "Warning: Note off for 41 on instrument 38 without matching note on.\n",
      "Warning: Note off for 39 on instrument 38 without matching note on.\n",
      "Warning: Note off for 59 on instrument 80 without matching note on.\n",
      "Warning: Note off for 40 on instrument 81 without matching note on.\n",
      "Warning: Note off for 39 on instrument 80 without matching note on.\n",
      "Warning: Note off for 71 on instrument 38 without matching note on.\n",
      "Warning: Note off for 60 on instrument 80 without matching note on.\n",
      "Warning: Note off for 91 on instrument 81 without matching note on.\n",
      "Warning: Note off for 75 on instrument 38 without matching note on.\n",
      "Warning: Note off for 41 on instrument 38 without matching note on.\n",
      "Warning: Note off for 75 on instrument 38 without matching note on.\n",
      "Warning: Note off for 39 on instrument 80 without matching note on.\n",
      "Warning: Note off for 65 on instrument 38 without matching note on.\n",
      "Warning: Note off for 60 on instrument 38 without matching note on.\n",
      "Warning: Note off for 81 on instrument 81 without matching note on.\n",
      "Warning: Note off for 58 on instrument 80 without matching note on.\n",
      "Warning: Note off for 44 on instrument 38 without matching note on.\n",
      "Warning: Note off for 60 on instrument 38 without matching note on.\n",
      "\n",
      "Generated MIDI saved as: generated_transformer_music.mid\n",
      "\n",
      "Generated sequence length: 4093 tokens\n",
      "Number of instruments: 4\n",
      "Total notes: 890\n",
      "Duration: 106.75 seconds (1.78 minutes)\n",
      "\n",
      "Instruments used:\n",
      "  - Reverse Cymbal: 288 notes\n",
      "  - Square Lead: 354 notes\n",
      "  - Synth Bass: 102 notes\n",
      "  - Saw Lead: 146 notes\n",
      "\n",
      "First 20 tokens:\n",
      "['<BOS>', 'note_on_14_instrument_121', 'time_shift_14', 'note_on_14_instrument_121', 'time_shift_2', 'note_on_14_instrument_121', 'time_shift_2', 'note_on_14_instrument_121', 'time_shift_1', 'note_off_2_instrument_121', 'note_on_8_instrument_121', 'note_on_43_instrument_38', 'time_shift_1', 'note_off_14_instrument_121', 'note_on_15_instrument_121', 'note_off_56_instrument_38', 'time_shift_1', 'note_off_56_instrument_80', 'note_on_67_instrument_80', 'note_off_67_instrument_80']\n",
      "\n",
      "Last 10 tokens:\n",
      "['time_shift_1', 'note_off_16_instrument_121', 'time_shift_12', 'note_off_11_instrument_121', 'time_shift_13', 'note_on_59_instrument_80', 'note_off_16_instrument_121', 'time_shift_18', 'note_on_55_instrument_80', 'time_shift_18']\n"
     ]
    }
   ],
   "source": [
    "# Copy and paste this code into a new cell in your Jupyter notebook\n",
    "# after the cell where you sample from small_transformer\n",
    "\n",
    "# Generate music from the transformer and save as MIDI\n",
    "print(\"Generating music from the transformer...\")\n",
    "start_token = VOCABULARY[BEGINNING_OF_SONG_TOKEN]\n",
    "\n",
    "# Generate sequence using the existing sample_transformer function\n",
    "generated_sequence = sample_transformer(\n",
    "    loaded_model, \n",
    "    start_token=start_token, \n",
    "    max_length=4092, \n",
    "    temperature=0.8, \n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Convert token IDs back to token strings\n",
    "generated_tokens = [ID_TO_TOKEN[token] for token in generated_sequence]\n",
    "\n",
    "# Check if we hit the end token\n",
    "if VOCABULARY[END_OF_SONG_TOKEN] in generated_sequence:\n",
    "    end_idx = generated_sequence.index(VOCABULARY[END_OF_SONG_TOKEN])\n",
    "    print(f\"Hit end token at position {end_idx}\")\n",
    "else:\n",
    "    print(\"Generated full sequence without hitting end token\")\n",
    "\n",
    "# Convert tokens to MIDI\n",
    "print(\"\\nConverting to MIDI...\")\n",
    "generated_midi = tokens_to_midi(generated_tokens)\n",
    "\n",
    "# Save the MIDI file\n",
    "output_filename = 'generated_transformer_music.mid'\n",
    "generated_midi.write(output_filename)\n",
    "print(f\"\\nGenerated MIDI saved as: {output_filename}\")\n",
    "\n",
    "# Display statistics about the generated music\n",
    "print(f\"\\nGenerated sequence length: {len(generated_sequence)} tokens\")\n",
    "print(f\"Number of instruments: {len(generated_midi.instruments)}\")\n",
    "\n",
    "if generated_midi.instruments:\n",
    "    total_notes = sum(len(inst.notes) for inst in generated_midi.instruments)\n",
    "    print(f\"Total notes: {total_notes}\")\n",
    "    \n",
    "    duration = generated_midi.get_end_time()\n",
    "    print(f\"Duration: {duration:.2f} seconds ({duration/60:.2f} minutes)\")\n",
    "    \n",
    "    # Show instrument breakdown\n",
    "    print(\"\\nInstruments used:\")\n",
    "    instrument_names = {\n",
    "        80: 'Square Lead', \n",
    "        81: 'Saw Lead', \n",
    "        38: 'Synth Bass', \n",
    "        121: 'Reverse Cymbal'\n",
    "    }\n",
    "    for inst in generated_midi.instruments:\n",
    "        inst_name = instrument_names.get(inst.program, f'Program {inst.program}')\n",
    "        print(f\"  - {inst_name}: {len(inst.notes)} notes\")\n",
    "\n",
    "# Show sample of generated tokens\n",
    "print(f\"\\nFirst 20 tokens:\")\n",
    "print(generated_tokens[:20])\n",
    "\n",
    "print(f\"\\nLast 10 tokens:\")\n",
    "print(generated_tokens[-10:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ca6df68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "11cbd79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving tiny_model...\n",
      "Model saved to tiny_transformer_checkpoint.pt\n",
      "Configuration saved: n_layer=3, d_model=256, d_inner=1024\n",
      "\n",
      "Loading model...\n",
      "Model loaded from tiny_transformer_checkpoint.pt\n",
      "Configuration: n_layer=3, d_model=256, d_inner=1024\n",
      "Resumed from epoch 100 with train loss: 2.3563, val loss: 2.5633\n",
      "\n",
      "Testing loaded model...\n",
      "Model output shape: torch.Size([1, 10, 1127])\n"
     ]
    }
   ],
   "source": [
    "def save_transformer_model(model, optimizer, epoch, train_loss, val_loss, filepath='transformer_checkpoint.pt'):\n",
    "    \"\"\"\n",
    "    Save model checkpoint with all necessary information for resuming training\n",
    "    \"\"\"\n",
    "    # Get d_inner from the first layer\n",
    "    first_layer = model.layers[0]\n",
    "    d_inner = first_layer.d_inner\n",
    "    \n",
    "    # Check if weights are tied\n",
    "    tie_weight = True  # Default assumption for MusicTransformer\n",
    "    if hasattr(model, 'out_layer') and hasattr(model.out_layer, 'weight'):\n",
    "        if hasattr(model.word_emb, 'weight'):\n",
    "            # Check if they point to the same tensor\n",
    "            tie_weight = model.out_layer.weight.data_ptr() == model.word_emb.weight.data_ptr()\n",
    "    \n",
    "    # Determine pre_lnorm by checking layer structure\n",
    "    pre_lnorm = False  # Default for most transformer implementations\n",
    "    \n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'model_config': {\n",
    "            'vocab_size': model.word_emb.num_embeddings,\n",
    "            'd_model': model.d_model,\n",
    "            'n_head': model.n_head,\n",
    "            'd_head': model.d_head,\n",
    "            'd_inner': d_inner,\n",
    "            'n_layer': model.n_layer,\n",
    "            'tgt_len': model.tgt_len,\n",
    "            'mem_len': model.mem_len,\n",
    "            'dropout': model.drop.p,\n",
    "            'tie_weight': tie_weight,\n",
    "            'pre_lnorm': pre_lnorm\n",
    "        }\n",
    "    }\n",
    "    torch.save(checkpoint, filepath)\n",
    "    print(f\"Model saved to {filepath}\")\n",
    "    print(f\"Configuration saved: n_layer={model.n_layer}, d_model={model.d_model}, d_inner={d_inner}\")\n",
    "\n",
    "def load_transformer_model(filepath='transformer_checkpoint.pt', device='cuda'):\n",
    "    \"\"\"\n",
    "    Load model checkpoint and create model with saved configuration\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(filepath, map_location=device, weights_only=False)\n",
    "    \n",
    "    if 'model_config' in checkpoint:\n",
    "        config = checkpoint['model_config']\n",
    "    else:\n",
    "        raise ValueError(\"No model configuration found in checkpoint\")\n",
    "    \n",
    "    # Create model\n",
    "    model = MusicTransformer(**config)\n",
    "    \n",
    "    # Load weights\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Create and load optimizer\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    print(f\"Model loaded from {filepath}\")\n",
    "    print(f\"Configuration: n_layer={config['n_layer']}, d_model={config['d_model']}, d_inner={config['d_inner']}\")\n",
    "    print(f\"Resumed from epoch {checkpoint['epoch']} with train loss: {checkpoint['train_loss']:.4f}, val loss: {checkpoint['val_loss']:.4f}\")\n",
    "    \n",
    "    return model, optimizer, checkpoint['epoch'], checkpoint['train_loss'], checkpoint['val_loss']\n",
    "\n",
    "# Simplified functions for common use cases\n",
    "def quick_save(model, filepath='model_checkpoint.pt', epoch=0):\n",
    "    \"\"\"Quick save without optimizer state\"\"\"\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    save_transformer_model(model, optimizer, epoch, 0.0, 0.0, filepath)\n",
    "\n",
    "def quick_load(filepath='model_checkpoint.pt', device='cuda'):\n",
    "    \"\"\"Quick load just the model\"\"\"\n",
    "    model, _, _, _, _ = load_transformer_model(filepath, device)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Modified training function that supports resuming\n",
    "def train_transformer_resume(model, train_loader, val_loader, vocab_size, \n",
    "                            num_epochs=20, lr=0.001, device='cuda', \n",
    "                            start_epoch=0, optimizer=None, checkpoint_path='transformer_checkpoint.pt',\n",
    "                            save_every_epoch=False):\n",
    "    \"\"\"\n",
    "    Training function with checkpoint saving and resume capability\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    pad_idx = VOCABULARY[PAD_TOKEN]\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "    \n",
    "    if optimizer is None:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        mems = None\n",
    "        \n",
    "        for i, batch in enumerate(train_loader):\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Reset memory if batch size changes\n",
    "            if mems is not None and mems[0].size(1) != inputs.size(0):\n",
    "                mems = None\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs, mems = model(inputs, mems=mems)\n",
    "            \n",
    "            if mems is not None:\n",
    "                mems = [m.detach() for m in mems]\n",
    "            \n",
    "            outputs = outputs.reshape(-1, vocab_size)\n",
    "            targets = targets.reshape(-1)\n",
    "            \n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "            print_progress_bar(i+1, len(train_loader), prefix='Training...')\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            mems = None\n",
    "            for i, batch in enumerate(val_loader):\n",
    "                inputs, targets = batch\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                if mems is not None and mems[0].size(1) != inputs.size(0):\n",
    "                    mems = None\n",
    "                \n",
    "                outputs, mems = model(inputs, mems=mems)\n",
    "                outputs = outputs.reshape(-1, vocab_size)\n",
    "                targets = targets.reshape(-1)\n",
    "                \n",
    "                loss = criterion(outputs, targets)\n",
    "                total_val_loss += loss.item()\n",
    "                \n",
    "                print_progress_bar(i+1, len(val_loader), prefix='Validating...')\n",
    "        \n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # Save checkpoint\n",
    "        if save_every_epoch or avg_val_loss < best_val_loss:\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                print(f\"New best validation loss: {best_val_loss:.4f}\")\n",
    "            save_transformer_model(model, optimizer, epoch+1, avg_train_loss, avg_val_loss, checkpoint_path)\n",
    "\n",
    "\n",
    "# Save your model\n",
    "print(\"Saving tiny_model...\")\n",
    "save_transformer_model(\n",
    "    loaded_model, \n",
    "    optimizer=optim.Adam(tiny_model.parameters()), \n",
    "    epoch=100,\n",
    "    train_loss=2.3563,\n",
    "    val_loss=2.5633,\n",
    "    filepath='tiny_transformer_checkpoint.pt'\n",
    ")\n",
    "\n",
    "# Load it back\n",
    "print(\"\\nLoading model...\")\n",
    "loaded_model, loaded_optimizer, start_epoch, last_train_loss, last_val_loss = load_transformer_model(\n",
    "    'tiny_transformer_checkpoint.pt', \n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Test it works\n",
    "print(\"\\nTesting loaded model...\")\n",
    "with torch.no_grad():\n",
    "    test_input = torch.randint(0, 1127, (1, 10)).to(device)\n",
    "    test_output, _ = loaded_model(test_input)\n",
    "    print(f\"Model output shape: {test_output.shape}\")\n",
    "\n",
    "# train_transformer_resume(\n",
    "#     loaded_model, \n",
    "#     train_loader, \n",
    "#     val_loader, \n",
    "#     vocab_size=len(VOCABULARY), \n",
    "#     num_epochs=start_epoch + 50,  # No curly braces\n",
    "#     device=device,                 # No curly braces\n",
    "#     start_epoch=start_epoch,       # No curly braces\n",
    "#     optimizer=loaded_optimizer,\n",
    "#     checkpoint_path='tiny_transformer_checkpoint.pt'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dec47d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, vocab_size, num_epochs=20, lr=0.001, device='cuda'):\n",
    "    time_start = time.time()\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # --------- Training ---------\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # batch = batch['input_ids'].to(device)  # (batch_size, seq_length)\n",
    "\n",
    "            # inputs = batch[:, :-1]\n",
    "            # targets = batch[:, 1:]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(inputs)\n",
    "\n",
    "            outputs = outputs.reshape(-1, vocab_size)\n",
    "            targets = targets.reshape(-1)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            print_progress_bar(i+1, len(train_loader), prefix='Training...')\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        # --------- Validation ---------\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(val_loader):\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                # batch = batch['input_ids'].to(device)\n",
    "\n",
    "                # inputs = batch[:, :-1]\n",
    "                # targets = batch[:, 1:]\n",
    "\n",
    "                outputs, _ = model(inputs)\n",
    "                outputs = outputs.reshape(-1, vocab_size)\n",
    "                targets = targets.reshape(-1)\n",
    "\n",
    "                loss = criterion(outputs, targets)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                print_progress_bar(i+1, len(val_loader), prefix='Validating...')\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "058266e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 1/20 | Train Loss: 7.0168 | Val Loss: 6.7814\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 2/20 | Train Loss: 6.7814 | Val Loss: 6.3470\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 3/20 | Train Loss: 6.3470 | Val Loss: 5.9521\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 4/20 | Train Loss: 5.9521 | Val Loss: 5.7736\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 5/20 | Train Loss: 5.7736 | Val Loss: 6.3756\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 6/20 | Train Loss: 6.3756 | Val Loss: 5.5341\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 7/20 | Train Loss: 5.5341 | Val Loss: 5.4947\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 8/20 | Train Loss: 5.4947 | Val Loss: 5.2929\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 9/20 | Train Loss: 5.2929 | Val Loss: 4.9569\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 10/20 | Train Loss: 4.9569 | Val Loss: 4.6240\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 11/20 | Train Loss: 4.6240 | Val Loss: 4.3646\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 12/20 | Train Loss: 4.3646 | Val Loss: 4.1791\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 13/20 | Train Loss: 4.1791 | Val Loss: 4.0561\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 14/20 | Train Loss: 4.0561 | Val Loss: 3.9845\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 15/20 | Train Loss: 3.9845 | Val Loss: 3.9523\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 16/20 | Train Loss: 3.9523 | Val Loss: 3.9438\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 17/20 | Train Loss: 3.9438 | Val Loss: 3.9410\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 18/20 | Train Loss: 3.9410 | Val Loss: 3.9308\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 19/20 | Train Loss: 3.9308 | Val Loss: 3.9120\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 20/20 | Train Loss: 3.9120 | Val Loss: 3.8837\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8  # You can adjust this depending on your GPU memory\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps'\n",
    "print(f'Using device: {device}')\n",
    "model = MusicRNN(vocab_size=len(VOCABULARY), embedding_dim=256, hidden_dim=512, num_layers=2)\n",
    "train(model, train_loader, val_loader, vocab_size=len(VOCABULARY), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "edd31755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, start_token, max_length=100, temperature=1.0, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    generated = [start_token]\n",
    "    input_token = torch.tensor([[start_token]], device=device)  # (1, 1)\n",
    "\n",
    "    hidden = None\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        output, hidden = model(input_token, hidden)  # output: (1, 1, vocab_size)\n",
    "        output = output[:, -1, :]  # take the last output\n",
    "        output = output / temperature  # adjust randomness\n",
    "\n",
    "        probs = F.softmax(output, dim=-1)  # (1, vocab_size)\n",
    "        next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "        generated.append(next_token)\n",
    "        if next_token == VOCABULARY[END_OF_SONG_TOKEN] or VOCABULARY[PAD_TOKEN]: # reach end of sequence\n",
    "          break\n",
    "\n",
    "        input_token = torch.tensor([[next_token]], device=device)\n",
    "\n",
    "    return generated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6396f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = VOCABULARY[BEGINNING_OF_SONG_TOKEN]\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "generated_sequence = sample(model, start_token, max_length=1024, device=device)\n",
    "generated_tokens = [ID_TO_TOKEN[token] for token in generated_sequence]\n",
    "tokens_reconstructed = tokens_to_midi(generated_tokens)\n",
    "tokens_reconstructed.write('generated_midi.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab520814",
   "metadata": {},
   "source": [
    "### Train Soloists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a2edbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_soloist_midi_files(filepaths, instrument_program):\n",
    "    valid_files = []\n",
    "    for i, filepath in enumerate(filepaths):\n",
    "        try:\n",
    "            midi_data = pretty_midi.PrettyMIDI(filepath)\n",
    "            if len(midi_data.instruments) > 0 and any(instrument.program == instrument_program for instrument in midi_data.instruments):\n",
    "                valid_files.append(filepath)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filepath}: {e}\")\n",
    "        print_progress_bar(i+1, len(filepaths), prefix='Validating MIDI files')\n",
    "    return valid_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7eeb113",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_instruments = [80, 81, 38, 121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "633e8ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating MIDI files |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating MIDI files |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating MIDI files |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating MIDI files |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating MIDI files |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating MIDI files |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating MIDI files |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating MIDI files |██████████████████████████████████████████████████| 100.0% Complete\n"
     ]
    }
   ],
   "source": [
    "soloist_80_midi_train_filepaths = valid_soloist_midi_files(midi_train_filepaths, instrument_program=80)\n",
    "soloist_81_midi_train_filepaths = valid_soloist_midi_files(midi_train_filepaths, instrument_program=81)\n",
    "soloist_38_midi_train_filepaths = valid_soloist_midi_files(midi_train_filepaths, instrument_program=38)\n",
    "soloist_121_midi_train_filepaths = valid_soloist_midi_files(midi_train_filepaths, instrument_program=121)\n",
    "\n",
    "soloist_80_midi_val_filepaths = valid_soloist_midi_files(midi_val_filepaths, instrument_program=80)\n",
    "soloist_81_midi_val_filepaths = valid_soloist_midi_files(midi_val_filepaths, instrument_program=81)\n",
    "soloist_38_midi_val_filepaths = valid_soloist_midi_files(midi_val_filepaths, instrument_program=38)\n",
    "soloist_121_midi_val_filepaths = valid_soloist_midi_files(midi_val_filepaths, instrument_program=121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a6b66e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soloist_vocabulary():\n",
    "    vocabulary = dict()\n",
    "    index = 0\n",
    "\n",
    "    for special_token in [PAD_TOKEN, BEGINNING_OF_SONG_TOKEN, END_OF_SONG_TOKEN]:\n",
    "        vocabulary[special_token] = index\n",
    "        index += 1\n",
    "\n",
    "    for time_shift in range(1, MAX_SHIFT_STEPS + 1):\n",
    "        vocabulary[f'time_shift_{time_shift}'] = index\n",
    "        index += 1\n",
    "\n",
    "    for action in [\"note_on\", \"note_off\"]:\n",
    "        for pitch in range(128):\n",
    "            vocabulary[f'{action}_{pitch}'] = index\n",
    "            index += 1\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d4f9a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soloist_id_to_token():\n",
    "    vocabulary = get_soloist_vocabulary()\n",
    "    return {v: k for k, v in vocabulary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e7e47dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soloist_midi_to_tokens(pm: pretty_midi.PrettyMIDI, instrument_program):\n",
    "    events = []\n",
    "\n",
    "    for instrument in pm.instruments:\n",
    "        if instrument.program == instrument_program:\n",
    "            for note in instrument.notes:\n",
    "                events.append((note.start, f'note_on_{note.pitch}'))\n",
    "                events.append((note.end, f'note_off_{note.pitch}'))\n",
    "        \n",
    "            break\n",
    "        \n",
    "    \n",
    "    events.sort()  # Sort by time\n",
    "\n",
    "    tokens = []\n",
    "    last_time = 0.0\n",
    "    for time, event in events:\n",
    "        delta = time - last_time\n",
    "        steps = max(round(delta / TIME_SHIFT_RESOLUTION), 1) # force at least 1 step (no side by side notes)\n",
    "\n",
    "        while steps > 0:\n",
    "            shift = min(steps, MAX_SHIFT_STEPS)\n",
    "            tokens.append(f'time_shift_{shift}')\n",
    "            steps -= shift\n",
    "        \n",
    "        tokens.append(event)\n",
    "        last_time = time\n",
    "    return [BEGINNING_OF_SONG_TOKEN] + tokens + [END_OF_SONG_TOKEN]\n",
    "\n",
    "def soloist_tokens_to_midi(tokens, instrument_program):\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    instrument = pretty_midi.Instrument(program=instrument_program)\n",
    "\n",
    "    active_notes = dict()\n",
    "    active_pitch = None\n",
    "    active_start = None\n",
    "\n",
    "    current_time = 0.0\n",
    "    for token in tokens:\n",
    "        # print(current_time, token)\n",
    "        if token.startswith('time_shift_'):\n",
    "            shift_steps = int(token.split('_')[-1])\n",
    "            current_time += shift_steps * TIME_SHIFT_RESOLUTION\n",
    "        elif token.startswith('note_on_'):\n",
    "            if active_pitch is not None:\n",
    "                print(f\"Warning: Skipping {token}, other note: {active_pitch} is still active.\")\n",
    "                continue \n",
    "            pitch = int(token.split('_')[2])\n",
    "            # active_notes[pitch] = current_time\n",
    "            active_pitch = pitch\n",
    "            active_start = current_time\n",
    "        elif token.startswith('note_off_'):\n",
    "            pitch = int(token.split('_')[2])\n",
    "            if pitch != active_pitch:\n",
    "                print(f\"Warning: Note off for {pitch} without matching note on.\")\n",
    "                continue\n",
    "\n",
    "            if current_time > active_start:\n",
    "                note = pretty_midi.Note(\n",
    "                    velocity=100, pitch=pitch, start=active_start, end=current_time\n",
    "                )\n",
    "\n",
    "                instrument.notes.append(note)\n",
    "            else:\n",
    "                print(f\"Warning: Note off for {pitch} at {current_time} note after note on at {active_start}. Ignoring.\")\n",
    "            # del active_notes[pitch]\n",
    "            active_pitch = None\n",
    "            active_start = None\n",
    "\n",
    "    pm.instruments.append(instrument)\n",
    "    \n",
    "    return pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e90aef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "midi = pretty_midi.PrettyMIDI(all_filepaths[0])\n",
    "tokens_80 = soloist_midi_to_tokens(midi, 80)\n",
    "tokens_81 = soloist_midi_to_tokens(midi, 81)\n",
    "tokens_38 = soloist_midi_to_tokens(midi, 38)\n",
    "tokens_121 = soloist_midi_to_tokens(midi, 121)\n",
    "\n",
    "midi_reconstructed_80 = soloist_tokens_to_midi(tokens_80, instrument_program=80)\n",
    "midi_reconstructed_81 = soloist_tokens_to_midi(tokens_81, instrument_program=81)\n",
    "midi_reconstructed_38 = soloist_tokens_to_midi(tokens_38, instrument_program=38)\n",
    "midi_reconstructed_121 = soloist_tokens_to_midi(tokens_121, instrument_program=121)\n",
    "\n",
    "# midi_reconstructed_80.write('reconstructed_midi_80.mid')\n",
    "# midi_reconstructed_81.write('reconstructed_midi_81.mid')\n",
    "# midi_reconstructed_38.write('reconstructed_midi_38.mid')\n",
    "# midi_reconstructed_121.write('reconstructed_midi_121.mid')\n",
    "\n",
    "# midi.write('original_midi.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7c3dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_soloist_sequences(filepaths, instrument_program):\n",
    "    vocabulary = get_soloist_vocabulary()\n",
    "    sequences = []\n",
    "    for i, filepath in enumerate(filepaths):\n",
    "        pm = pretty_midi.PrettyMIDI(filepath)\n",
    "        tokens = soloist_midi_to_tokens(pm, instrument_program)\n",
    "        if not tokens:\n",
    "            raise ValueError(f'No tokens generated for {filepath}')\n",
    "        sequences.append([vocabulary[token] for token in tokens])\n",
    "        print_progress_bar(i+1, len(filepaths), prefix='Loading sequences')\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "38e9e573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sequences |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Loading sequences |██████████████████--------------------------------| 36.9% Complete\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m soloist_80_train_sequences \u001b[38;5;241m=\u001b[39m load_soloist_sequences(soloist_80_midi_train_filepaths, instrument_program\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m soloist_81_train_sequences \u001b[38;5;241m=\u001b[39m \u001b[43mload_soloist_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43msoloist_81_midi_train_filepaths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstrument_program\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m81\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m soloist_38_train_sequences \u001b[38;5;241m=\u001b[39m load_soloist_sequences(soloist_38_midi_train_filepaths, instrument_program\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m38\u001b[39m)\n\u001b[1;32m      4\u001b[0m soloist_121_train_sequences \u001b[38;5;241m=\u001b[39m load_soloist_sequences(soloist_121_midi_train_filepaths, instrument_program\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m121\u001b[39m)\n",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m, in \u001b[0;36mload_soloist_sequences\u001b[0;34m(filepaths, instrument_program)\u001b[0m\n\u001b[1;32m      3\u001b[0m sequences \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, filepath \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(filepaths):\n\u001b[0;32m----> 5\u001b[0m     pm \u001b[38;5;241m=\u001b[39m \u001b[43mpretty_midi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPrettyMIDI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m soloist_midi_to_tokens(pm, instrument_program)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tokens:\n",
      "File \u001b[0;32m~/Desktop/ucsd/cse_253/cse153-group-project/.env/lib/python3.10/site-packages/pretty_midi/pretty_midi.py:107\u001b[0m, in \u001b[0;36mPrettyMIDI.__init__\u001b[0;34m(self, midi_file, resolution, initial_tempo)\u001b[0m\n\u001b[1;32m    100\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    101\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTempo, Key or Time signature change events found on \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero tracks.  This is not a valid type 0 or type 1 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMIDI file.  Tempo, Key or Time Signature may be wrong.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    104\u001b[0m             \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m)\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# Populate the list of instruments\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_instruments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmidi_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolution \u001b[38;5;241m=\u001b[39m resolution\n",
      "File \u001b[0;32m~/Desktop/ucsd/cse_253/cse153-group-project/.env/lib/python3.10/site-packages/pretty_midi/pretty_midi.py:410\u001b[0m, in \u001b[0;36mPrettyMIDI._load_instruments\u001b[0;34m(self, midi_data)\u001b[0m\n\u001b[1;32m    407\u001b[0m program \u001b[38;5;241m=\u001b[39m current_instrument[event\u001b[38;5;241m.\u001b[39mchannel]\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Retrieve the Instrument instance for the current inst\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# Don't create a new instrument if none exists\u001b[39;00m\n\u001b[0;32m--> 410\u001b[0m instrument \u001b[38;5;241m=\u001b[39m \u001b[43m__get_instrument\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchannel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;66;03m# Add the control change event\u001b[39;00m\n\u001b[1;32m    413\u001b[0m instrument\u001b[38;5;241m.\u001b[39mcontrol_changes\u001b[38;5;241m.\u001b[39mappend(control_change)\n",
      "File \u001b[0;32m~/Desktop/ucsd/cse_253/cse153-group-project/.env/lib/python3.10/site-packages/pretty_midi/pretty_midi.py:278\u001b[0m, in \u001b[0;36mPrettyMIDI._load_instruments.<locals>.__get_instrument\u001b[0;34m(program, channel, track, create_new)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;66;03m# This dict will map track indices to any track names encountered\u001b[39;00m\n\u001b[1;32m    276\u001b[0m track_name_map \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mdefaultdict(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m--> 278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__get_instrument\u001b[39m(program, channel, track, create_new):\n\u001b[1;32m    279\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Gets the Instrument corresponding to the given program number,\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;124;03m    drum/non-drum type, channel, and track index.  If no such\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m    instrument exists, one is created.\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;66;03m# If we have already created an instrument for this program\u001b[39;00m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# number/track/channel, return it\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "soloist_80_train_sequences = load_soloist_sequences(soloist_80_midi_train_filepaths, instrument_program=80)\n",
    "soloist_81_train_sequences = load_soloist_sequences(soloist_81_midi_train_filepaths, instrument_program=81)\n",
    "soloist_38_train_sequences = load_soloist_sequences(soloist_38_midi_train_filepaths, instrument_program=38)\n",
    "soloist_121_train_sequences = load_soloist_sequences(soloist_121_midi_train_filepaths, instrument_program=121)\n",
    "\n",
    "soloist_80_val_sequences = load_soloist_sequences(soloist_80_midi_val_filepaths, instrument_program=80)\n",
    "soloist_81_val_sequences = load_soloist_sequences(soloist_81_midi_val_filepaths, instrument_program=81)\n",
    "soloist_38_val_sequences = load_soloist_sequences(soloist_38_midi_val_filepaths, instrument_program=38)\n",
    "soloist_121_val_sequences = load_soloist_sequences(soloist_121_midi_val_filepaths, instrument_program=121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2796bd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soloist_model():\n",
    "    return MusicRNN(vocab_size=len(get_soloist_vocabulary()), embedding_dim=64, hidden_dim=512, num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa97d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_soloists(soloist_sequences: dict):\n",
    "    models = {}\n",
    "    for instrument_program, (train_sequences, val_sequences) in soloist_sequences.items():\n",
    "        train_dataset = MIDITokenDataset(train_sequences[:2], seq_length=512)\n",
    "        val_dataset = MIDITokenDataset(val_sequences[:2], seq_length=512)\n",
    "\n",
    "        batch_size = 8\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        model = get_soloist_model()\n",
    "        train(model, train_loader, val_loader, vocab_size=len(get_soloist_vocabulary()), device=device)\n",
    "        models[instrument_program] = model\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ffb7c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sequences |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Processing sequences |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 1/20 | Train Loss: 5.8776 | Val Loss: 5.7679\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 2/20 | Train Loss: 5.7679 | Val Loss: 5.5858\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 3/20 | Train Loss: 5.5858 | Val Loss: 5.1507\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 4/20 | Train Loss: 5.1507 | Val Loss: 4.3661\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 5/20 | Train Loss: 4.3661 | Val Loss: 3.4084\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 6/20 | Train Loss: 3.4084 | Val Loss: 3.1842\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 7/20 | Train Loss: 3.1842 | Val Loss: 3.0075\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 8/20 | Train Loss: 3.0075 | Val Loss: 2.9587\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 9/20 | Train Loss: 2.9587 | Val Loss: 2.9178\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 10/20 | Train Loss: 2.9178 | Val Loss: 2.8779\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 11/20 | Train Loss: 2.8779 | Val Loss: 2.8408\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 12/20 | Train Loss: 2.8408 | Val Loss: 2.8067\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 13/20 | Train Loss: 2.8067 | Val Loss: 2.7853\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 14/20 | Train Loss: 2.7853 | Val Loss: 2.7752\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 15/20 | Train Loss: 2.7752 | Val Loss: 2.7672\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 16/20 | Train Loss: 2.7672 | Val Loss: 2.7562\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 17/20 | Train Loss: 2.7562 | Val Loss: 2.7497\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 18/20 | Train Loss: 2.7497 | Val Loss: 2.7405\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 19/20 | Train Loss: 2.7405 | Val Loss: 2.7309\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 20/20 | Train Loss: 2.7309 | Val Loss: 2.7229\n",
      "Processing sequences |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Processing sequences |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 1/20 | Train Loss: 5.8806 | Val Loss: 5.6658\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 2/20 | Train Loss: 5.6658 | Val Loss: 5.1944\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 3/20 | Train Loss: 5.1944 | Val Loss: 4.1828\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 4/20 | Train Loss: 4.1828 | Val Loss: 3.7824\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 5/20 | Train Loss: 3.7824 | Val Loss: 4.0817\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 6/20 | Train Loss: 4.0817 | Val Loss: 3.6576\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 7/20 | Train Loss: 3.6576 | Val Loss: 3.6842\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 8/20 | Train Loss: 3.6842 | Val Loss: 3.6430\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 9/20 | Train Loss: 3.6430 | Val Loss: 3.5201\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 10/20 | Train Loss: 3.5201 | Val Loss: 3.2785\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 11/20 | Train Loss: 3.2785 | Val Loss: 2.9619\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 12/20 | Train Loss: 2.9619 | Val Loss: 2.6919\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 13/20 | Train Loss: 2.6919 | Val Loss: 2.4986\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 14/20 | Train Loss: 2.4986 | Val Loss: 2.3700\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 15/20 | Train Loss: 2.3700 | Val Loss: 2.2956\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 16/20 | Train Loss: 2.2956 | Val Loss: 2.2647\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 17/20 | Train Loss: 2.2647 | Val Loss: 2.2611\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 18/20 | Train Loss: 2.2611 | Val Loss: 2.2663\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 19/20 | Train Loss: 2.2663 | Val Loss: 2.2671\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 20/20 | Train Loss: 2.2671 | Val Loss: 2.2593\n",
      "Processing sequences |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Processing sequences |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 1/20 | Train Loss: 5.8834 | Val Loss: 5.7525\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 2/20 | Train Loss: 5.7525 | Val Loss: 5.5441\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 3/20 | Train Loss: 5.5441 | Val Loss: 5.0311\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 4/20 | Train Loss: 5.0311 | Val Loss: 4.1291\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 5/20 | Train Loss: 4.1291 | Val Loss: 3.0675\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 6/20 | Train Loss: 3.0675 | Val Loss: 2.9079\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 7/20 | Train Loss: 2.9079 | Val Loss: 3.6112\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 8/20 | Train Loss: 3.6112 | Val Loss: 2.6482\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 9/20 | Train Loss: 2.6482 | Val Loss: 2.8645\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 10/20 | Train Loss: 2.8645 | Val Loss: 2.8884\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 11/20 | Train Loss: 2.8884 | Val Loss: 2.8661\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 12/20 | Train Loss: 2.8661 | Val Loss: 2.8329\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 13/20 | Train Loss: 2.8329 | Val Loss: 2.7931\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 14/20 | Train Loss: 2.7931 | Val Loss: 2.7502\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 15/20 | Train Loss: 2.7502 | Val Loss: 2.7134\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 16/20 | Train Loss: 2.7134 | Val Loss: 2.6793\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 17/20 | Train Loss: 2.6793 | Val Loss: 2.6515\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 18/20 | Train Loss: 2.6515 | Val Loss: 2.6286\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 19/20 | Train Loss: 2.6286 | Val Loss: 2.6086\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 20/20 | Train Loss: 2.6086 | Val Loss: 2.5900\n",
      "Processing sequences |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Processing sequences |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 1/20 | Train Loss: 5.8902 | Val Loss: 5.7496\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 2/20 | Train Loss: 5.7496 | Val Loss: 5.5045\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 3/20 | Train Loss: 5.5045 | Val Loss: 5.0392\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 4/20 | Train Loss: 5.0392 | Val Loss: 4.6197\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 5/20 | Train Loss: 4.6197 | Val Loss: 6.4634\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 6/20 | Train Loss: 6.4634 | Val Loss: 3.4162\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 7/20 | Train Loss: 3.4162 | Val Loss: 2.9930\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 8/20 | Train Loss: 2.9930 | Val Loss: 2.6489\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 9/20 | Train Loss: 2.6489 | Val Loss: 2.4528\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 10/20 | Train Loss: 2.4528 | Val Loss: 2.3339\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 11/20 | Train Loss: 2.3339 | Val Loss: 2.2371\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 12/20 | Train Loss: 2.2371 | Val Loss: 2.1609\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 13/20 | Train Loss: 2.1609 | Val Loss: 2.1037\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 14/20 | Train Loss: 2.1037 | Val Loss: 2.0597\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 15/20 | Train Loss: 2.0597 | Val Loss: 2.0260\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 16/20 | Train Loss: 2.0260 | Val Loss: 1.9989\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 17/20 | Train Loss: 1.9989 | Val Loss: 1.9742\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 18/20 | Train Loss: 1.9742 | Val Loss: 1.9542\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 19/20 | Train Loss: 1.9542 | Val Loss: 1.9315\n",
      "Training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Validating... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 20/20 | Train Loss: 1.9315 | Val Loss: 1.9140\n"
     ]
    }
   ],
   "source": [
    "soloist_sequences = {\n",
    "    80: (soloist_80_train_sequences, soloist_80_val_sequences),\n",
    "    81: (soloist_81_train_sequences, soloist_81_val_sequences),\n",
    "    38: (soloist_38_train_sequences, soloist_38_val_sequences),\n",
    "    121: (soloist_121_train_sequences, soloist_121_val_sequences)\n",
    "}\n",
    "soloist_models = train_soloists(soloist_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "619737a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_weights(models):\n",
    "    for instrument_program, model in models.items():\n",
    "        torch.save(model.state_dict(), f'soloist_model_{instrument_program}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9592015",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_weights(soloist_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7bdb8225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_weight(path, model):\n",
    "    model.load_state_dict(torch.load(path, map_location='cpu'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "57ca8e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_soloists(models, outdir='./'):\n",
    "    soloist_vocabulary = get_soloist_vocabulary()\n",
    "    midis = dict()\n",
    "    for instrument_program, model in models.items():\n",
    "        model.eval()  # Set to eval mode for inference\n",
    "        start_token = soloist_vocabulary[BEGINNING_OF_SONG_TOKEN]\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        generated_sequence = sample(model, start_token, max_length=1024, device=device)\n",
    "        generated_tokens = [get_soloist_id_to_token()[token] for token in generated_sequence]\n",
    "        tokens_reconstructed = soloist_tokens_to_midi(generated_tokens, instrument_program=instrument_program)\n",
    "        midis[instrument_program] = tokens_reconstructed\n",
    "    \n",
    "    together_midi = pretty_midi.PrettyMIDI()\n",
    "    for instrument_program, midi in midis.items():\n",
    "        together_midi.instruments.extend(midi.instruments)\n",
    "\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    outpath = os.path.join(outdir, f'{datetime.datetime.now()}.mid')\n",
    "    \n",
    "    together_midi.write(outpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c66c021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [load_model_weight(f'soloist_model_{instrument_program}.pth', get_soloist_model()) for instrument_program in unique_instruments]\n",
    "model_weights_dir = os.path.join('lstm_models', 'soloists', '2')\n",
    "# models = {80: load_model_weight(os.path.join(model_weights_dir, 'soloist_model_80.pth'), get_soloist_model())}\n",
    "models = {instr_program: load_model_weight(os.path.join(model_weights_dir, f'soloist_model_{instr_program}.pth'), get_soloist_model()) for instr_program in unique_instruments}\n",
    "sample_soloists(models, outdir=os.path.join(model_weights_dir, 'samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ec73ec8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting side by side notes |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Side by side note count: 121967\n",
      "Total tokens: 2057224\n"
     ]
    }
   ],
   "source": [
    "side_by_side_note_count = 0\n",
    "total_tokens = 0\n",
    "for i, sequence in enumerate(soloist_80_train_sequences):\n",
    "    pairwise = zip(sequence[:-1], sequence[1:])\n",
    "    total_tokens += len(sequence)\n",
    "    for token1, token2 in pairwise:\n",
    "        token1 = get_soloist_id_to_token()[token1]\n",
    "        token2 = get_soloist_id_to_token()[token2]\n",
    "        if token1.startswith('note_on_') and token2.startswith('note_off_'):\n",
    "            if token1.split('_')[2] == token2.split('_')[2]:\n",
    "                side_by_side_note_count += 1\n",
    "\n",
    "    print_progress_bar(i+1, len(soloist_80_train_sequences), prefix='Counting side by side notes')\n",
    "    \n",
    "print(f'Side by side note count: {side_by_side_note_count}')\n",
    "print(f'Total tokens: {total_tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d8ddea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7125c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd8e32c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
