{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a57a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install miditoolkit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba0a244f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcfriedman/magenta_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from miditoolkit import MidiFile, Note, Instrument\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import subprocess\n",
    "import datetime\n",
    "from miditok import REMI, TokenizerConfig\n",
    "from miditok.pytorch_data import DatasetMIDI, DataCollator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f27e858-b131-4b50-8eaf-da34fc5e869f",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fcd4bb4-4c63-4fc2-8f91-0105468bf36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress_bar(iteration, total, prefix='', length=50):\n",
    "    percent = (\"{0:.1f}\").format(100 * (iteration / float(total)))\n",
    "    filled_length = int(length * iteration // total)\n",
    "    bar = '█' * filled_length + '-' * (length - filled_length)\n",
    "    print(f'\\r{prefix} |{bar}| {percent}% Complete', end='\\r', flush=True)\n",
    "    if iteration == total:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d55e0a90-2926-4c6b-b0ad-c598770d4bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_midi_objs(filepaths: list, num_samples: int = 100) -> list: \n",
    "    sampled_filepaths = random.sample(filepaths, num_samples)\n",
    "    midis = []\n",
    "    for i, filepath in enumerate(sampled_filepaths):\n",
    "        print_progress_bar(i + 1, num_samples, prefix='Converting .mid files to MidiFile')\n",
    "        try:\n",
    "            midi = MidiFile(filepath)\n",
    "            midis.append(midi)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filepath}: {e}\")\n",
    "        \n",
    "    return midis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c64c6a",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b01840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_dirpath = 'nesmdb_midi/'\n",
    "midi_train_dirpath = os.path.join(midi_dirpath, 'train')\n",
    "midi_test_dirpath = os.path.join(midi_dirpath, 'test')\n",
    "midi_val_dirpath = os.path.join(midi_dirpath, 'valid')\n",
    "midi_train_filesnames = os.listdir(midi_train_dirpath)\n",
    "midi_test_filesnames = os.listdir(midi_test_dirpath)\n",
    "midi_val_filenames = os.listdir(midi_val_dirpath)\n",
    "\n",
    "midi_train_filepaths = [os.path.join(midi_train_dirpath, filename) for filename in midi_train_filesnames]\n",
    "midi_test_filepaths = [os.path.join(midi_test_dirpath, filename) for filename in midi_test_filesnames]\n",
    "midi_val_filepaths = [os.path.join(midi_val_dirpath, filename) for filename in midi_val_filenames]\n",
    "all_filepaths = midi_train_filepaths + midi_test_filepaths + midi_val_filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc4d1332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_files 4502\n",
      "num_test_files 373\n",
      "num_val_files 403\n",
      "total_files 5278\n"
     ]
    }
   ],
   "source": [
    "print(\"num_train_files\", len(midi_train_filepaths))\n",
    "print(\"num_test_files\", len(midi_test_filepaths))\n",
    "print(\"num_val_files\", len(midi_val_filepaths))\n",
    "print(\"total_files\", len(all_filepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97cc8a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting .mid files to MidiFile |██████████████████████████████████████████████████| 100.0% Complete\n"
     ]
    }
   ],
   "source": [
    "midis = to_midi_objs(all_filepaths, num_samples=len(all_filepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bcca336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instrument count distribution: {2: 598, 3: 1730, 4: 2821, 1: 125, 0: 4}\n",
      "Unique instruments: {80, 81, 38, 121}\n",
      "Unique instruments distribution: {80: 5075, 38: 4676, 81: 4970, 121: 3074}\n",
      "Instrument set distribution: {(38, 80): 126, (38, 80, 81): 1519, (38, 80, 81, 121): 2821, (38, 80, 121): 57, (80, 81, 121): 114, (80, 81): 382, (38, 81): 61, (81,): 28, (38, 81, 121): 40, (80,): 47, (121,): 13, (): 4, (38, 121): 15, (38,): 37, (80, 121): 9, (81, 121): 5}\n",
      "Number of tempo changes: Counter({1: 5278})\n",
      "Tempo distribution: Counter({120.0: 5278})\n",
      "ticks_per_sec_dist: Counter({22050: 5278})\n"
     ]
    }
   ],
   "source": [
    "instrument_count_distribution = Counter(len(midi.instruments) for midi in midis)\n",
    "unique_instruments = set([int(instrument.program) for midi in midis for instrument in midi.instruments])\n",
    "unique_instruments_distribution = Counter([int(instrument.program) for midi in midis for instrument in midi.instruments])\n",
    "instrument_sets_distribution = Counter(tuple(sorted([int(instrument.program) for instrument in midi.instruments])) for midi in midis)\n",
    "number_of_tempo_changes = Counter([len(m.tempo_changes) for m in midis])\n",
    "tempo_dist = Counter(c.tempo for m in midis for c in m.tempo_changes)\n",
    "ticks_per_sec_dist = Counter(m.ticks_per_beat for m in midis)\n",
    "print(\"Instrument count distribution:\", dict(instrument_count_distribution))\n",
    "print(\"Unique instruments:\", unique_instruments)\n",
    "print(\"Unique instruments distribution:\", dict(unique_instruments_distribution))\n",
    "print(\"Instrument set distribution:\", dict(instrument_sets_distribution))\n",
    "print(\"Number of tempo changes:\", number_of_tempo_changes)\n",
    "print(\"Tempo distribution:\", tempo_dist)\n",
    "print(\"ticks_per_sec_dist:\", ticks_per_sec_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a38d7555-48cf-4d1a-88a5-a95e5f7485e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max duration: 1517.683560090703\n",
      "90th percentile duration: 64.9059365079365\n"
     ]
    }
   ],
   "source": [
    "midis_with_instr = [m for m in midis if len(m.instruments)]\n",
    "def piece_duration(midi_obj):\n",
    "    ticks_per_beat = 22050\n",
    "    bpm = 120\n",
    "    bps = bpm / 60\n",
    "    max_tick = max(note.end for inst in midi_obj.instruments for note in inst.notes)\n",
    "    piece_duration_in_s = max_tick / ticks_per_beat / bps\n",
    "    return piece_duration_in_s\n",
    "\n",
    "durations = [piece_duration(m) for m in midis_with_instr]\n",
    "print(\"max duration:\", max(durations))\n",
    "print(\"90th percentile duration:\", np.percentile(durations, 90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceea6167-7a2f-4844-97e9-1787cbfe181e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticks per beat: 22050\n",
       "max tick: 282514\n",
       "tempo changes: 1\n",
       "time sig: 2\n",
       "key sig: 0\n",
       "markers: 0\n",
       "lyrics: False\n",
       "instruments: 3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midis[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816eb63a",
   "metadata": {},
   "source": [
    "### Custom LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2027f6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
    "        super(MusicRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        # x: (batch_size, seq_length)\n",
    "        x = self.embedding(x)  # (batch_size, seq_length, embedding_dim)\n",
    "        out, hidden = self.rnn(x, hidden)  # out: (batch_size, seq_length, hidden_dim)\n",
    "        out = self.fc(out)  # (batch_size, seq_length, vocab_size)\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "883abdd1-a42c-4cc8-80df-9def87e8f755",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMIDITokenizer( ):\n",
    "    def __init__(self, time_divisions=100, time_shift_increment=0.01, target_instrument=80):\n",
    "        self.time_divisions = time_divisions\n",
    "        self.time_shift_increment = time_shift_increment\n",
    "        self.special_tokens = {\n",
    "            \"PAD\": 0,\n",
    "            \"BOS\": 1,\n",
    "            \"EOS\": 2,\n",
    "        }\n",
    "        \n",
    "        self.ticks_per_beat = 22050 # from data exploration\n",
    "        self.bpm = 120 # from data exploration\n",
    "        self.target_instrument = target_instrument\n",
    "        \n",
    "        self.note_on_offset = 3\n",
    "        self.note_off_offset = self.note_on_offset + 128\n",
    "        self.time_offset = self.note_off_offset + 128\n",
    "        self.vocab_size = self.time_offset + self.time_divisions + 1\n",
    "\n",
    "    def quantize_duration(self, delta_seconds):\n",
    "        idx = int(delta_seconds / self.time_shift_increment)\n",
    "        return min(idx, self.time_divisions - 1)  # Cap at 99\n",
    "\n",
    "    def get_note_on_token(self, note):\n",
    "        return self.note_on_offset + note\n",
    "\n",
    "    def get_note_off_token(self, note):\n",
    "        return self.note_off_offset + note\n",
    "\n",
    "    def get_time_shift_token(self, quantized_delta):\n",
    "        return self.time_offset + quantized_delta\n",
    "        \n",
    "        \n",
    "    def get_quantized_time_shift_deltas(self, prev_event_time_in_s, next_event_time_in_s):\n",
    "        quantized_times = []\n",
    "        while next_event_time_in_s - prev_event_time_in_s > self.time_shift_increment:\n",
    "            delta = next_event_time_in_s - prev_event_time_in_s\n",
    "            prev_event_time_in_s += min(delta, self.time_divisions * self.time_shift_increment)\n",
    "            quantized = self.quantize_duration(delta)\n",
    "            quantized_times.append(quantized)\n",
    "        return quantized_times\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return self.special_tokens[item.split(\"_\")[0]]\n",
    "\n",
    "    @property\n",
    "    def pad_token_id(self):\n",
    "        return self.special_tokens[\"PAD\"]\n",
    "    \n",
    "    def encode(self, midi_obj):\n",
    "        ticks_per_beat = midi_obj.ticks_per_beat\n",
    "        bps = self.bpm / 60\n",
    "\n",
    "        targets = list(filter(lambda x: x.program == self.target_instrument, list(midi_obj.instruments)))\n",
    "\n",
    "        max_tick = max(note.end for inst in midi_obj.instruments for note in inst.notes)\n",
    "        piece_duration_in_s = max_tick / ticks_per_beat / bps\n",
    "\n",
    "        note_events = []\n",
    "        if len(targets):\n",
    "            for note in targets[0].notes:\n",
    "                start_time_in_s = note.start / ticks_per_beat / bps\n",
    "                end_time_in_s = note.end / ticks_per_beat / bps\n",
    "                if end_time_in_s - start_time_in_s >= self.time_shift_increment:\n",
    "                    note_events.append((start_time_in_s, note.pitch, \"start\"))\n",
    "                    note_events.append((end_time_in_s, note.pitch, \"end\"))\n",
    "     \n",
    "        \n",
    "        note_events = sorted(note_events)\n",
    "        \n",
    "        debug_tokens = []\n",
    "        prev_time = 0.0\n",
    "        for time_start, pitch, action in note_events:\n",
    "            times_shift_deltas = self.get_quantized_time_shift_deltas(prev_time, time_start)\n",
    "            for delta in times_shift_deltas:\n",
    "                ts_token = self.get_time_shift_token(delta)\n",
    "                debug_tokens.append((ts_token, \"time_shift_token\"))\n",
    "            prev_time = time_start\n",
    "\n",
    "            if (action == \"start\"):\n",
    "                debug_tokens.append((self.get_note_on_token(pitch), \"note_on\"))\n",
    "            else:\n",
    "                debug_tokens.append((self.get_note_off_token(pitch), \"note_off\"))\n",
    "\n",
    "        \n",
    "        # print(debug_tokens)\n",
    "        tokens = [t[0] for t in debug_tokens]\n",
    "        \n",
    "        return tokens\n",
    "\n",
    "    def decode(self, tokens, output_path):\n",
    "        midi_obj = MidiFile()\n",
    "        instrument = Instrument(program=self.target_instrument, is_drum=False)\n",
    "\n",
    "        current_time = 0.0 # in seconds\n",
    "        active_notes = {}\n",
    "\n",
    "        ticks_per_second = self.ticks_per_beat * self.bpm / 60\n",
    "        \n",
    "        for token in tokens:\n",
    "            if token == self.special_tokens[\"BOS\"]:\n",
    "                continue # handle BOS\n",
    "                \n",
    "            elif token == self.special_tokens[\"EOS\"]: \n",
    "                continue # handle EOS\n",
    "                \n",
    "            elif token == self.special_tokens[\"PAD\"]: # will model output PAD tokens?\n",
    "                continue # handle PAD\n",
    "                \n",
    "            elif token < self.note_off_offset: # are note pitches 0 indexed?\n",
    "                # handle token is a note start event\n",
    "                pitch = token - self.note_on_offset\n",
    "                active_notes[pitch] = current_time\n",
    "                \n",
    "            elif token < self.time_offset: # are note pitches 0 indexed?\n",
    "               # handle token is a note end event\n",
    "                pitch = token - self.note_off_offset\n",
    "                if pitch in active_notes:\n",
    "                    start = active_notes.pop(pitch)\n",
    "                    end = current_time\n",
    "                    note = Note(\n",
    "                        pitch=pitch,\n",
    "                        start=int(start * ticks_per_second),\n",
    "                        end=int(end * ticks_per_second),\n",
    "                        velocity=100,  # constant velocity\n",
    "                    )\n",
    "                    instrument.notes.append(note)\n",
    "                \n",
    "            elif token < self.vocab_size:\n",
    "                # handle token is a time shift event\n",
    "                shift_amount = (token - self.time_offset + 1) * 0.01\n",
    "                current_time += shift_amount\n",
    "                \n",
    "            else:\n",
    "                raise Exception(\"unknown token value: \" + token)\n",
    "\n",
    "        midi_obj.instruments.append(instrument)\n",
    "        midi_obj.ticks_per_beat = self.ticks_per_beat\n",
    "        midi_obj.dump(output_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "726a2ea0-a65d-4981-91d6-a2af8466acca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "target_instrument = 80 # unique instruments = 80, 81, 38, 121\n",
    "tokenizer = CustomMIDITokenizer(target_instrument=target_instrument)\n",
    "midi_obj = midis[150]\n",
    "tokens = tokenizer.encode(midi_obj)\n",
    "print(len(tokens))\n",
    "tokenizer.decode(tokens, f\"decoded_{target_instrument}.mid\") \n",
    "midi_obj.dump(\"original.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf43ed04-dd27-4251-8b27-e2c7d44fd88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 53791\n",
      "90th percentile length: 922.6999999999998\n",
      "failed midis:  4\n"
     ]
    }
   ],
   "source": [
    "tokenizer = CustomMIDITokenizer()\n",
    "\n",
    "lengths = []\n",
    "failed_count = 0\n",
    "for m in midis:\n",
    "    try: \n",
    "        tokens = tokenizer.encode(m)\n",
    "        lengths.append(len(tokens))\n",
    "    except Exception:\n",
    "        failed_count += 1\n",
    "\n",
    "print(\"max length:\", max(lengths))\n",
    "print(\"90th percentile length:\", np.percentile(lengths, 90))\n",
    "print(\"failed midis: \", failed_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76b9f9d5-7fe5-4447-ab12-5f9fba3b3b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIDIDataset(Dataset):\n",
    "    def __init__(self, file_paths, tokenizer, max_seq_len, midi_objs):\n",
    "        self.file_paths = file_paths\n",
    "        self.midi_objs = midi_objs\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.bos_token = tokenizer[\"BOS_None\"]\n",
    "        self.eos_token = tokenizer[\"EOS_None\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.midi_objs)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        midi_obj = self.midi_objs[idx]\n",
    "        tokens = self.tokenizer.encode(midi_obj)\n",
    "        tokens = [self.bos_token] + tokens + [self.eos_token]\n",
    "        tokens = tokens[:self.max_seq_len]  # truncate if needed\n",
    "        \n",
    "        return torch.tensor(tokens, dtype=torch.long)\n",
    "\n",
    "def safe_collate(batch, pad_token_id=0):\n",
    "    # Remove None items (failed MIDI files)\n",
    "    batch = [b for b in batch if b is not None]\n",
    "    if not batch:\n",
    "        print(\"NO NOT NONE BATCH!\")\n",
    "        return {\"input_ids\": torch.empty(0, dtype=torch.long)}\n",
    "\n",
    "    lengths = [len(x) for x in batch]\n",
    "    max_len = max(lengths)\n",
    "\n",
    "    padded = torch.full((len(batch), max_len), pad_token_id, dtype=torch.long)\n",
    "    for i, seq in enumerate(batch):\n",
    "        padded[i, :len(seq)] = seq\n",
    "\n",
    "    return {\"input_ids\": padded}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8093675e-9a70-48f9-9e0c-3dc38388f95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting .mid files to MidiFile |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Converting .mid files to MidiFile |██████████████████████████████████████████████████| 100.0% Complete\n"
     ]
    }
   ],
   "source": [
    "train_midi_objs = to_midi_objs(midi_train_filepaths, num_samples=len(midi_train_filepaths))\n",
    "test_midi_objs = to_midi_objs(midi_test_filepaths, num_samples=len(midi_test_filepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35c3b5aa-681b-45a9-b7d1-81074269446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_midi_objs = list(filter(lambda midi_obj: len(midi_obj.instruments) > 0, train_midi_objs))\n",
    "test_midi_objs = list(filter(lambda midi_obj: len(midi_obj.instruments) > 0, test_midi_objs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3df388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, vocab_size, num_epochs=20, lr=0.001, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "    patience = 2  # or any number of your choice\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        # --------- Training ---------\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            print_progress_bar(i + 1, len(train_loader), \"training...\")\n",
    "            batch = batch['input_ids'].to(device)  # (batch_size, seq_length)\n",
    "            \n",
    "            if batch.ndim != 2:\n",
    "                print(f\"Malformed train batch at epoch {epoch}, step {i}: shape={batch.shape}\")\n",
    "            \n",
    "            inputs = batch[:, :-1]\n",
    "            targets = batch[:, 1:]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(inputs)\n",
    "            outputs = outputs.reshape(-1, vocab_size)\n",
    "            targets = targets.reshape(-1)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        # --------- Validation ---------\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        total_correct = 0\n",
    "        total_tokens = 0        \n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(val_loader):\n",
    "                print_progress_bar(i + 1, len(val_loader), \"validation...\")\n",
    "                batch = batch['input_ids'].to(device)\n",
    "                if batch.ndim != 2:\n",
    "                    print(f\"Malformed val batch at epoch {epoch}, step {i}: shape={batch.shape}\")\n",
    "                \n",
    "                inputs = batch[:, :-1]\n",
    "                targets = batch[:, 1:]\n",
    "\n",
    "                outputs, _ = model(inputs)\n",
    "                outputs = outputs.reshape(-1, vocab_size)\n",
    "                targets = targets.reshape(-1)\n",
    "\n",
    "                loss = criterion(outputs, targets)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                predicted = torch.argmax(outputs, dim=1)\n",
    "                total_correct += (predicted == targets).sum().item()\n",
    "                total_tokens += targets.numel()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        accuracy = total_correct / total_tokens\n",
    "        duration = time.time() - start_time\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Accuracy: {accuracy:.4f} | Time: {duration:.2f}s\")\n",
    "\n",
    "        # stop early if we haven't improved\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_without_improvement = 0\n",
    "            # Optionally save the model\n",
    "            torch.save(model.state_dict(), \"best_model.pt\")\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "        \n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1} due to no improvement in validation loss.\")\n",
    "            print(f\"Best val_loss: {best_val_loss}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e603d6e-8177-48a5-ae88-09b96a2f0ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING INSTRUMENT: 80\n",
      "\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 1/20 | Train Loss: 2.1544 | Val Loss: 1.4168 | Accuracy: 0.7068 | Time: 12.83s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 2/20 | Train Loss: 1.2961 | Val Loss: 1.0791 | Accuracy: 0.7567 | Time: 12.36s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 3/20 | Train Loss: 1.1014 | Val Loss: 1.0065 | Accuracy: 0.7611 | Time: 12.44s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 4/20 | Train Loss: 1.0334 | Val Loss: 0.9236 | Accuracy: 0.7714 | Time: 12.62s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 5/20 | Train Loss: 0.9937 | Val Loss: 0.9236 | Accuracy: 0.7759 | Time: 12.68s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 6/20 | Train Loss: 0.9774 | Val Loss: 0.8734 | Accuracy: 0.7894 | Time: 12.61s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 7/20 | Train Loss: 0.9487 | Val Loss: 0.8638 | Accuracy: 0.7892 | Time: 12.96s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 8/20 | Train Loss: 0.9209 | Val Loss: 0.8538 | Accuracy: 0.7913 | Time: 12.93s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 9/20 | Train Loss: 0.9106 | Val Loss: 0.8586 | Accuracy: 0.7891 | Time: 12.96s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 10/20 | Train Loss: 0.8836 | Val Loss: 0.8809 | Accuracy: 0.7830 | Time: 13.13s\n",
      "Early stopping at epoch 10 due to no improvement in validation loss.\n",
      "Best val_loss: 0.8538388984818612\n",
      "\n",
      "\n",
      "TRAINING INSTRUMENT: 81\n",
      "\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 1/20 | Train Loss: 2.1388 | Val Loss: 1.3824 | Accuracy: 0.7179 | Time: 12.02s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 2/20 | Train Loss: 1.2714 | Val Loss: 1.0631 | Accuracy: 0.7629 | Time: 11.40s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 3/20 | Train Loss: 1.0821 | Val Loss: 0.9597 | Accuracy: 0.7705 | Time: 11.70s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 4/20 | Train Loss: 1.0065 | Val Loss: 0.8949 | Accuracy: 0.7816 | Time: 11.78s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 5/20 | Train Loss: 0.9775 | Val Loss: 0.8746 | Accuracy: 0.7801 | Time: 11.43s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 6/20 | Train Loss: 0.9346 | Val Loss: 0.8638 | Accuracy: 0.7872 | Time: 11.43s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 7/20 | Train Loss: 0.9145 | Val Loss: 0.8608 | Accuracy: 0.7804 | Time: 11.56s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 8/20 | Train Loss: 0.8994 | Val Loss: 0.8893 | Accuracy: 0.7750 | Time: 11.73s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 9/20 | Train Loss: 0.8887 | Val Loss: 0.8026 | Accuracy: 0.7955 | Time: 11.35s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 10/20 | Train Loss: 0.8720 | Val Loss: 0.8233 | Accuracy: 0.7890 | Time: 11.71s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 11/20 | Train Loss: 0.8648 | Val Loss: 0.7845 | Accuracy: 0.8006 | Time: 12.30s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 12/20 | Train Loss: 0.8582 | Val Loss: 0.8389 | Accuracy: 0.7908 | Time: 12.37s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 13/20 | Train Loss: 0.8560 | Val Loss: 0.7821 | Accuracy: 0.7991 | Time: 12.85s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 14/20 | Train Loss: 0.8443 | Val Loss: 0.8315 | Accuracy: 0.7920 | Time: 12.70s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 15/20 | Train Loss: 0.8328 | Val Loss: 0.8235 | Accuracy: 0.7897 | Time: 12.79s\n",
      "Early stopping at epoch 15 due to no improvement in validation loss.\n",
      "Best val_loss: 0.782125352210896\n",
      "\n",
      "\n",
      "TRAINING INSTRUMENT: 38\n",
      "\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 1/20 | Train Loss: 2.1552 | Val Loss: 1.1509 | Accuracy: 0.7559 | Time: 12.65s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 2/20 | Train Loss: 1.2171 | Val Loss: 0.8966 | Accuracy: 0.7958 | Time: 12.51s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 3/20 | Train Loss: 1.0313 | Val Loss: 0.8179 | Accuracy: 0.8035 | Time: 12.96s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 4/20 | Train Loss: 0.9460 | Val Loss: 0.7365 | Accuracy: 0.8212 | Time: 13.22s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 5/20 | Train Loss: 0.9018 | Val Loss: 0.7259 | Accuracy: 0.8247 | Time: 12.91s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 6/20 | Train Loss: 0.8615 | Val Loss: 0.7119 | Accuracy: 0.8264 | Time: 13.89s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 7/20 | Train Loss: 0.8390 | Val Loss: 0.6964 | Accuracy: 0.8281 | Time: 13.21s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 8/20 | Train Loss: 0.8220 | Val Loss: 0.6831 | Accuracy: 0.8340 | Time: 13.64s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 9/20 | Train Loss: 0.7940 | Val Loss: 0.6633 | Accuracy: 0.8311 | Time: 14.01s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 10/20 | Train Loss: 0.7832 | Val Loss: 0.6565 | Accuracy: 0.8355 | Time: 14.49s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 11/20 | Train Loss: 0.7878 | Val Loss: 0.7361 | Accuracy: 0.8281 | Time: 13.43s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 12/20 | Train Loss: 0.7624 | Val Loss: 0.6255 | Accuracy: 0.8403 | Time: 13.37s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 13/20 | Train Loss: 0.7576 | Val Loss: 0.6371 | Accuracy: 0.8342 | Time: 14.52s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 14/20 | Train Loss: 0.7528 | Val Loss: 0.6575 | Accuracy: 0.8369 | Time: 14.52s\n",
      "Early stopping at epoch 14 due to no improvement in validation loss.\n",
      "Best val_loss: 0.6255093758465141\n",
      "\n",
      "\n",
      "TRAINING INSTRUMENT: 121\n",
      "\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 1/20 | Train Loss: 1.4565 | Val Loss: 0.9205 | Accuracy: 0.7930 | Time: 15.05s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 2/20 | Train Loss: 0.7927 | Val Loss: 0.7228 | Accuracy: 0.8228 | Time: 14.86s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 3/20 | Train Loss: 0.6606 | Val Loss: 0.6754 | Accuracy: 0.8330 | Time: 15.34s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 4/20 | Train Loss: 0.5904 | Val Loss: 0.6089 | Accuracy: 0.8424 | Time: 15.60s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 5/20 | Train Loss: 0.5493 | Val Loss: 0.5868 | Accuracy: 0.8455 | Time: 15.39s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 6/20 | Train Loss: 0.5152 | Val Loss: 0.5789 | Accuracy: 0.8525 | Time: 16.17s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 7/20 | Train Loss: 0.4913 | Val Loss: 0.5376 | Accuracy: 0.8580 | Time: 15.71s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 8/20 | Train Loss: 0.4705 | Val Loss: 0.5095 | Accuracy: 0.8662 | Time: 15.24s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 9/20 | Train Loss: 0.4506 | Val Loss: 0.5190 | Accuracy: 0.8681 | Time: 15.48s\n",
      "training... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "validation... |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Epoch 10/20 | Train Loss: 0.4433 | Val Loss: 0.5111 | Accuracy: 0.8612 | Time: 16.15s\n",
      "Early stopping at epoch 10 due to no improvement in validation loss.\n",
      "Best val_loss: 0.5095321999121738\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = dict()\n",
    "target_instruments = [80, 81, 38, 121]\n",
    "# target_instruments = [80]\n",
    "for target_instrument in target_instruments:\n",
    "    try:\n",
    "        print(f\"TRAINING INSTRUMENT: {target_instrument}\\n\")\n",
    "        MAX_SEQUENCE_LENGTH = 512\n",
    "        tokenizer = CustomMIDITokenizer(target_instrument=target_instrument)\n",
    "        pad_token_id = tokenizer.pad_token_id  # or hardcoded if you want\n",
    "    \n",
    "        train_dataset = MIDIDataset(midi_train_filepaths, tokenizer, MAX_SEQUENCE_LENGTH, train_midi_objs)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: safe_collate(x, pad_token_id))\n",
    "    \n",
    "        test_dataset = MIDIDataset(midi_test_filepaths, tokenizer, MAX_SEQUENCE_LENGTH, test_midi_objs)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: safe_collate(x, pad_token_id))\n",
    "    \n",
    "        vocab_size = tokenizer.vocab_size\n",
    "        embedding_dim = 256\n",
    "        # hidden_dim = 512\n",
    "        # hidden_dim = 256\n",
    "        hidden_dim = 64 # matching the NES MDB paper\n",
    "        num_layers = 2\n",
    "\n",
    "        model = MusicRNN(vocab_size, embedding_dim, hidden_dim, num_layers)\n",
    "        train(model, train_loader, test_loader, vocab_size)\n",
    "        models[target_instrument] = model\n",
    "        print(\"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"target {target_instrument} failed\", e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ba34559-2acc-43b3-a6a3-80ad31e06b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_weights(models):\n",
    "    out_dir = os.path.join(\"weights\", str(datetime.datetime.now()))\n",
    "    os.mkdir(out_dir)\n",
    "    for target_instrument, model in models.items():\n",
    "        out_path = os.path.join(out_dir, f\"instrument_{target_instrument}.pth\")\n",
    "        torch.save(model.state_dict(), out_path)\n",
    "save_model_weights(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1e321c9-9d14-4e09-b9c2-3d043ede506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, start_token, max_length=100, temperature=1.0, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    generated = [start_token]\n",
    "    input_token = torch.tensor([[start_token]], device=device)  # (1, 1)\n",
    "\n",
    "    hidden = None\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        output, hidden = model(input_token, hidden)  # output: (1, 1, vocab_size)\n",
    "        output = output[:, -1, :]  # take the last output\n",
    "        output = output / temperature  # adjust randomness\n",
    "\n",
    "        probs = F.softmax(output, dim=-1)  # (1, vocab_size)\n",
    "        next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "        generated.append(next_token)\n",
    "        if next_token == 2 or next_token == 0: # reach end of sequence\n",
    "          break\n",
    "\n",
    "        input_token = torch.tensor([[next_token]], device=device)\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "81d64771-eecb-4192-ae3b-582ef5e1206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_models(models):\n",
    "    out_dir = os.path.join(\"samples\", str(datetime.datetime.now()))\n",
    "    os.mkdir(out_dir)\n",
    "    for target_instrument, model in models.items():\n",
    "        tokenizer = CustomMIDITokenizer(target_instrument=target_instrument)\n",
    "        start_token = tokenizer.special_tokens[\"BOS\"]\n",
    "        generated_sequence = sample(model, start_token, max_length=1024)\n",
    "        out_path = os.path.join(out_dir, f\"instrument_{target_instrument}.mid\")\n",
    "        torch.save(model.state_dict(), out_path)\n",
    "        tokenizer.decode(generated_sequence, out_path)\n",
    "\n",
    "sample_models(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d1487dc3-ddee-4dc0-bf06-fd175a4a3818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BREAK 10241\n",
      "10241\n"
     ]
    }
   ],
   "source": [
    "start_token = tokenizer.special_tokens[\"BOS\"]\n",
    "generated_sequence = sample(model, start_token, max_length=1024 * 20, min_length=1024 * 10)\n",
    "print(len(generated_sequence))\n",
    "tokenizer.decode(generated_sequence, \"rnn_2048_long.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "af81c10e-635e-41c6-b0e0-be2afaaf8cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from miditoolkit import MidiFile\n",
    "\n",
    "samples_dir = 'samples'\n",
    "\n",
    "for folder_name in os.listdir(samples_dir):\n",
    "    folder_path = os.path.join(samples_dir, folder_name)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "\n",
    "    combined_midi = MidiFile()\n",
    "    instruments = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if not file_name.endswith('.mid'):\n",
    "            continue\n",
    "\n",
    "        midi_path = os.path.join(folder_path, file_name)\n",
    "        midi = MidiFile(midi_path)\n",
    "        instruments.extend(midi.instruments)\n",
    "\n",
    "        # Use the first valid ticks_per_beat\n",
    "        if combined_midi.ticks_per_beat == 480:\n",
    "            combined_midi.ticks_per_beat = midi.ticks_per_beat\n",
    "\n",
    "    combined_midi.instruments = instruments\n",
    "    combined_path = os.path.join(folder_path, 'all.mid')\n",
    "    combined_midi.dump(combined_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Magenta Env",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
